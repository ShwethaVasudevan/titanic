{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing dataset from csv files\n",
    "\n",
    "train_data = pd.read_csv('train.csv')\n",
    "test_data = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId      0\n",
       "Survived         0\n",
       "Pclass           0\n",
       "Name             0\n",
       "Sex              0\n",
       "Age            177\n",
       "SibSp            0\n",
       "Parch            0\n",
       "Ticket           0\n",
       "Fare             0\n",
       "Cabin          687\n",
       "Embarked         2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking columns for missing values\n",
    "# train_data - Null values exist in columns Age, Cabin and Embarked\n",
    "\n",
    "train_data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId      0\n",
       "Pclass           0\n",
       "Name             0\n",
       "Sex              0\n",
       "Age             86\n",
       "SibSp            0\n",
       "Parch            0\n",
       "Ticket           0\n",
       "Fare             1\n",
       "Cabin          327\n",
       "Embarked         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Pclass  Survived\n",
      "0       1  0.629630\n",
      "1       2  0.472826\n",
      "2       3  0.242363\n"
     ]
    }
   ],
   "source": [
    "# Passenger Class\n",
    "\n",
    "print(train_data[[\"Pclass\", \"Survived\"]].groupby([\"Pclass\"], as_index = False).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Sex  Survived\n",
      "0  female  0.742038\n",
      "1    male  0.188908\n"
     ]
    }
   ],
   "source": [
    "# Sex\n",
    "\n",
    "print(train_data[[\"Sex\", \"Survived\"]].groupby([\"Sex\"], as_index = False).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   family_size  Survived\n",
      "0            1  0.303538\n",
      "1            2  0.552795\n",
      "2            3  0.578431\n",
      "3            4  0.724138\n",
      "4            5  0.200000\n",
      "5            6  0.136364\n",
      "6            7  0.333333\n",
      "7            8  0.000000\n",
      "8           11  0.000000\n"
     ]
    }
   ],
   "source": [
    "# Feature Engineering with the help of SibSp and Parch\n",
    "# New feature can be Family Size \n",
    "\n",
    "train_data['family_size'] = 0\n",
    "test_data['family_size'] = 0\n",
    "\n",
    "train_data['family_size'] = train_data['SibSp'] + train_data['Parch'] + 1\n",
    "test_data['family_size'] = test_data['SibSp'] + test_data['Parch'] + 1\n",
    "\n",
    "print(train_data[[\"family_size\",\"Survived\"]].groupby([\"family_size\"], as_index = False).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>family_size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  family_size  \n",
       "0      0         A/5 21171   7.2500   NaN        S            2  \n",
       "1      0          PC 17599  71.2833   C85        C            2  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S            1  \n",
       "3      0            113803  53.1000  C123        S            2  \n",
       "4      0            373450   8.0500   NaN        S            1  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a new column 'is_alone' to check survival of passengers travelling alone\n",
    "\n",
    "def check_alone(row): \n",
    "    \"\"\"Check whether a passenger travelled alone (returns 1) or with family (returns 0).\n",
    "    \n",
    "    \"\"\"\n",
    "    if row['family_size'] == 1:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "train_data['is_alone'] = train_data.apply(check_alone, axis = 1)\n",
    "test_data['is_alone'] = test_data.apply(check_alone, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   is_alone  Survived\n",
      "0         0  0.505650\n",
      "1         1  0.303538\n"
     ]
    }
   ],
   "source": [
    "print(train_data[[\"is_alone\", \"Survived\"]].groupby([\"is_alone\"], as_index = False).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>family_size</th>\n",
       "      <th>is_alone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>62</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Icard, Miss. Amelie</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>113572</td>\n",
       "      <td>80.0</td>\n",
       "      <td>B28</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>829</th>\n",
       "      <td>830</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Stone, Mrs. George Nelson (Martha Evelyn)</td>\n",
       "      <td>female</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>113572</td>\n",
       "      <td>80.0</td>\n",
       "      <td>B28</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Survived  Pclass                                       Name  \\\n",
       "61            62         1       1                        Icard, Miss. Amelie   \n",
       "829          830         1       1  Stone, Mrs. George Nelson (Martha Evelyn)   \n",
       "\n",
       "        Sex   Age  SibSp  Parch  Ticket  Fare Cabin Embarked  family_size  \\\n",
       "61   female  38.0      0      0  113572  80.0   B28      NaN            1   \n",
       "829  female  62.0      0      0  113572  80.0   B28      NaN            1   \n",
       "\n",
       "     is_alone  \n",
       "61          1  \n",
       "829         1  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Embarked\n",
    "# TODO: Fill the 2 NaN values\n",
    "\n",
    "e = train_data[train_data.Embarked.isna()]\n",
    "e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Both rows have the same Fare value\n",
    "# Range of values for 'C' satisfies the given fare values.\n",
    "# Setting a limit on the range of the y-axis\n",
    "\n",
    "plt.ylim(0,200)\n",
    "ax = sns.boxplot(x = train_data['Embarked'], y = train_data['Fare'], palette = 'GnBu')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill NaN values with 'C'\n",
    "train_data['Embarked'] = train_data[\"Embarked\"].fillna('C')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>family_size</th>\n",
       "      <th>is_alone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>62</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Icard, Miss. Amelie</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>113572</td>\n",
       "      <td>80.0</td>\n",
       "      <td>B28</td>\n",
       "      <td>C</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>829</th>\n",
       "      <td>830</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Stone, Mrs. George Nelson (Martha Evelyn)</td>\n",
       "      <td>female</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>113572</td>\n",
       "      <td>80.0</td>\n",
       "      <td>B28</td>\n",
       "      <td>C</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Survived  Pclass                                       Name  \\\n",
       "61            62         1       1                        Icard, Miss. Amelie   \n",
       "829          830         1       1  Stone, Mrs. George Nelson (Martha Evelyn)   \n",
       "\n",
       "        Sex   Age  SibSp  Parch  Ticket  Fare Cabin Embarked  family_size  \\\n",
       "61   female  38.0      0      0  113572  80.0   B28        C            1   \n",
       "829  female  62.0      0      0  113572  80.0   B28        C            1   \n",
       "\n",
       "     is_alone  \n",
       "61          1  \n",
       "829         1  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.iloc[[61,829],:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Embarked  Survived\n",
      "0        C  0.558824\n",
      "1        Q  0.389610\n",
      "2        S  0.336957\n"
     ]
    }
   ],
   "source": [
    "print(train_data[['Embarked','Survived']].groupby(['Embarked'], as_index = False).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Age\n",
    "# NaN values filled with random number between (avg - avg std. deviation) and (avg + avg std. deviation)\n",
    "# 177\n",
    "\n",
    "avg = train_data['Age'].mean()\n",
    "std = train_data['Age'].std()\n",
    "# random = np.random.randint(avg - std, avg + std, size = 177) # to fill\n",
    "random = np.array([36, 37, 34, 31, 33, 22, 22, 37, 18, 16, 38, 29, 38, 19, 42, 39, 39,\n",
    "       28, 27, 20, 35, 41, 27, 38, 28, 34, 18, 31, 31, 15, 36, 21, 35, 23,\n",
    "       22, 40, 24, 36, 26, 28, 15, 40, 36, 19, 23, 39, 30, 29, 33, 35, 21,\n",
    "       17, 42, 25, 41, 38, 25, 21, 22, 16, 43, 17, 32, 40, 18, 39, 31, 17,\n",
    "       27, 19, 41, 30, 29, 25, 42, 25, 43, 16, 41, 17, 15, 43, 27, 40, 38,\n",
    "       40, 41, 36, 21, 21, 33, 36, 35, 17, 35, 30, 19, 43, 30, 28, 18, 38,\n",
    "       36, 25, 16, 34, 34, 34, 36, 38, 21, 38, 23, 15, 41, 28, 28, 32, 16,\n",
    "       34, 31, 15, 17, 20, 18, 37, 31, 41, 16, 23, 25, 43, 16, 35, 39, 35,\n",
    "       15, 37, 43, 22, 23, 21, 29, 19, 42, 40, 37, 30, 25, 27, 39, 35, 36,\n",
    "       38, 19, 31, 26, 30, 16, 20, 30, 15, 18, 43, 40, 21, 22, 31, 29, 32,\n",
    "       30, 18, 35, 16, 18, 31, 23])\n",
    "\n",
    "train_data.loc[train_data.Age.isna(), 'Age'] = random    # fill with random age values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: repeat for test_Data\n",
    "\n",
    "avg = test_data['Age'].mean()\n",
    "std = test_data['Age'].std()\n",
    "#random = np.random.randint(avg - std, avg + std, size = 86)\n",
    "random = np.array([36, 16, 29, 34, 30, 42, 27, 34, 26, 28, 26, 29, 42, 38, 33, 23, 30,\n",
    "       23, 18, 35, 43, 26, 34, 23, 38, 27, 40, 37, 32, 35, 22, 23, 40, 42,\n",
    "       41, 33, 21, 23, 35, 16, 23, 39, 24, 28, 36, 43, 35, 21, 36, 37, 24,\n",
    "       33, 31, 37, 39, 27, 40, 35, 26, 28, 18, 33, 40, 16, 43, 25, 34, 17,\n",
    "       21, 18, 27, 18, 28, 30, 21, 35, 22, 36, 19, 42, 18, 37, 23, 43, 32,\n",
    "       25])\n",
    "test_data.loc[test_data.Age.isna(), 'Age'] = random\n",
    "test_data.Age.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    category_age  Survived\n",
      "0  (-0.08, 16.0]  0.491379\n",
      "1   (16.0, 32.0]  0.356979\n",
      "2   (32.0, 48.0]  0.379845\n",
      "3   (48.0, 64.0]  0.434783\n",
      "4   (64.0, 80.0]  0.090909\n"
     ]
    }
   ],
   "source": [
    "# pd.cut() - useful for going from a continuous variable to a categorical variable. \n",
    "# Used here to convert ages to groups of age ranges.\n",
    "\n",
    "train_data.Age = train_data['Age'].astype(int)    # convert to int to create bins easily\n",
    "test_data.Age = test_data['Age'].astype(int)\n",
    "train_data['category_age'] = pd.cut(train_data['Age'], 5)    # 5 bins\n",
    "print(train_data[[\"category_age\",\"Survived\"]].groupby([\"category_age\"], as_index = False).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     category_fare  Survived\n",
      "0   (-0.001, 7.91]  0.197309\n",
      "1   (7.91, 14.454]  0.303571\n",
      "2   (14.454, 31.0]  0.454955\n",
      "3  (31.0, 512.329]  0.581081\n"
     ]
    }
   ],
   "source": [
    "# Fare\n",
    "\n",
    "train_data['category_fare'] = pd.qcut(train_data['Fare'], 4)\n",
    "print(train_data[['category_fare', 'Survived']].groupby([\"category_fare\"], as_index = False).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152    S\n",
      "Name: Embarked, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Replace NaN in test_data Fare column\n",
    "\n",
    "print(test_data.loc[test_data.Fare.isna(), 'Embarked'])    # Get Embarked value for NaN Fare\n",
    "mean = train_data.loc[train_data.Embarked == 'S', 'Fare'].mean()    # Calculate mean for 'S' fares\n",
    "test_data.loc[test_data.Fare.isna(), 'Fare'] = mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>family_size</th>\n",
       "      <th>is_alone</th>\n",
       "      <th>category_age</th>\n",
       "      <th>category_fare</th>\n",
       "      <th>Title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>(16.0, 32.0]</td>\n",
       "      <td>(-0.001, 7.91]</td>\n",
       "      <td>Mr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>(32.0, 48.0]</td>\n",
       "      <td>(31.0, 512.329]</td>\n",
       "      <td>Mrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>(16.0, 32.0]</td>\n",
       "      <td>(7.91, 14.454]</td>\n",
       "      <td>Miss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>(32.0, 48.0]</td>\n",
       "      <td>(31.0, 512.329]</td>\n",
       "      <td>Mrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>(32.0, 48.0]</td>\n",
       "      <td>(7.91, 14.454]</td>\n",
       "      <td>Mr</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex  Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male   22      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female   38      1   \n",
       "2                             Heikkinen, Miss. Laina  female   26      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female   35      1   \n",
       "4                           Allen, Mr. William Henry    male   35      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  family_size  is_alone  \\\n",
       "0      0         A/5 21171   7.2500   NaN        S            2         0   \n",
       "1      0          PC 17599  71.2833   C85        C            2         0   \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S            1         1   \n",
       "3      0            113803  53.1000  C123        S            2         0   \n",
       "4      0            373450   8.0500   NaN        S            1         1   \n",
       "\n",
       "   category_age    category_fare Title  \n",
       "0  (16.0, 32.0]   (-0.001, 7.91]    Mr  \n",
       "1  (32.0, 48.0]  (31.0, 512.329]   Mrs  \n",
       "2  (16.0, 32.0]   (7.91, 14.454]  Miss  \n",
       "3  (32.0, 48.0]  (31.0, 512.329]   Mrs  \n",
       "4  (32.0, 48.0]   (7.91, 14.454]    Mr  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Name\n",
    "\n",
    "def get_title(row):\n",
    "    name = row['Name']\n",
    "    title_search = re.search('([A-Za-z]+)\\.', name)    # start with any letter, end with period\n",
    "    if title_search:\n",
    "        return title_search.group(1)    # .group() returns the strings that were matches\n",
    "    return \"\"\n",
    "\n",
    "train_data['Title'] = train_data.apply(get_title, axis = 1)\n",
    "test_data['Title'] = test_data.apply(get_title, axis = 1)\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Title  Survived\n",
      "0       Capt  0.000000\n",
      "1        Col  0.500000\n",
      "2   Countess  1.000000\n",
      "3        Don  0.000000\n",
      "4         Dr  0.428571\n",
      "5   Jonkheer  0.000000\n",
      "6       Lady  1.000000\n",
      "7      Major  0.500000\n",
      "8     Master  0.575000\n",
      "9       Miss  0.697802\n",
      "10      Mlle  1.000000\n",
      "11       Mme  1.000000\n",
      "12        Mr  0.156673\n",
      "13       Mrs  0.792000\n",
      "14        Ms  1.000000\n",
      "15       Rev  0.000000\n",
      "16       Sir  1.000000\n"
     ]
    }
   ],
   "source": [
    "print(train_data[['Title','Survived']].groupby(['Title'], as_index = False).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Narrowing the titles down further\n",
    "\n",
    "train_data['Title'] = train_data['Title'].replace(['Lady', 'Countess','Capt', 'Col','Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'],'Other')\n",
    "train_data['Title'] = train_data['Title'].replace(['Mlle', 'Ms'], 'Miss')\n",
    "train_data['Title'] = train_data['Title'].replace(['Mme'], 'Mrs')\n",
    "\n",
    "test_data['Title'] = test_data['Title'].replace(['Lady', 'Countess','Capt', 'Col','Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'],'Other')\n",
    "test_data['Title'] = test_data['Title'].replace(['Mlle', 'Ms'], 'Miss')\n",
    "test_data['Title'] = test_data['Title'].replace(['Mme'], 'Mrs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Mr        517\n",
       "Miss      185\n",
       "Mrs       126\n",
       "Master     40\n",
       "Other      23\n",
       "Name: Title, dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.Title.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Title  Survived\n",
      "0  Master  0.575000\n",
      "1    Miss  0.702703\n",
      "2      Mr  0.156673\n",
      "3     Mrs  0.793651\n",
      "4   Other  0.347826\n"
     ]
    }
   ],
   "source": [
    "print(train_data[['Title','Survived']].groupby(['Title'], as_index = False).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label Encoding\n",
    "\n",
    "# Sex\n",
    "sex_map = {'female': 0, 'male': 1}\n",
    "train_data['Sex'] = train_data.Sex.map(sex_map).astype(int)\n",
    "test_data['Sex'] = test_data.Sex.map(sex_map).astype(int)\n",
    "\n",
    "# Title\n",
    "title_map = {'Master': 0, 'Miss': 1, 'Mr': 2, 'Mrs': 3, 'Other': 4}\n",
    "train_data[\"Title\"] = train_data.Title.map(title_map).astype(int)\n",
    "test_data[\"Title\"] = test_data.Title.map(title_map).astype(int)\n",
    "\n",
    "# Embarked\n",
    "emb_map = {'C': 0, 'Q': 1, 'S': 2}\n",
    "train_data[\"Embarked\"] = train_data.Embarked.map(emb_map).astype(int)\n",
    "test_data[\"Embarked\"] = test_data.Embarked.map(emb_map).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>family_size</th>\n",
       "      <th>is_alone</th>\n",
       "      <th>category_age</th>\n",
       "      <th>category_fare</th>\n",
       "      <th>Title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>(16.0, 32.0]</td>\n",
       "      <td>(-0.001, 7.91]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>(32.0, 48.0]</td>\n",
       "      <td>(31.0, 512.329]</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>(16.0, 32.0]</td>\n",
       "      <td>(7.91, 14.454]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>(32.0, 48.0]</td>\n",
       "      <td>(31.0, 512.329]</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>1</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>(32.0, 48.0]</td>\n",
       "      <td>(7.91, 14.454]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name  Sex  Age  SibSp  Parch  \\\n",
       "0                            Braund, Mr. Owen Harris    1   22      1      0   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...    0   38      1      0   \n",
       "2                             Heikkinen, Miss. Laina    0   26      0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)    0   35      1      0   \n",
       "4                           Allen, Mr. William Henry    1   35      0      0   \n",
       "\n",
       "             Ticket     Fare Cabin  Embarked  family_size  is_alone  \\\n",
       "0         A/5 21171   7.2500   NaN         2            2         0   \n",
       "1          PC 17599  71.2833   C85         0            2         0   \n",
       "2  STON/O2. 3101282   7.9250   NaN         2            1         1   \n",
       "3            113803  53.1000  C123         2            2         0   \n",
       "4            373450   8.0500   NaN         2            1         1   \n",
       "\n",
       "   category_age    category_fare  Title  \n",
       "0  (16.0, 32.0]   (-0.001, 7.91]      2  \n",
       "1  (32.0, 48.0]  (31.0, 512.329]      3  \n",
       "2  (16.0, 32.0]   (7.91, 14.454]      1  \n",
       "3  (32.0, 48.0]  (31.0, 512.329]      3  \n",
       "4  (32.0, 48.0]   (7.91, 14.454]      2  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Age</th>\n",
       "      <th>Fare</th>\n",
       "      <th>family_size</th>\n",
       "      <th>Pclass_2</th>\n",
       "      <th>Pclass_3</th>\n",
       "      <th>Sex_1</th>\n",
       "      <th>Embarked_1</th>\n",
       "      <th>Embarked_2</th>\n",
       "      <th>is_alone_1</th>\n",
       "      <th>Title_1</th>\n",
       "      <th>Title_2</th>\n",
       "      <th>Title_3</th>\n",
       "      <th>Title_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>38</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>26</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>35</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Survived  Age     Fare  family_size  Pclass_2  Pclass_3  Sex_1  Embarked_1  \\\n",
       "0         0   22   7.2500            2         0         1      1           0   \n",
       "1         1   38  71.2833            2         0         0      0           0   \n",
       "2         1   26   7.9250            1         0         1      0           0   \n",
       "3         1   35  53.1000            2         0         0      0           0   \n",
       "4         0   35   8.0500            1         0         1      1           0   \n",
       "\n",
       "   Embarked_2  is_alone_1  Title_1  Title_2  Title_3  Title_4  \n",
       "0           1           0        0        1        0        0  \n",
       "1           0           0        0        0        1        0  \n",
       "2           1           1        1        0        0        0  \n",
       "3           1           0        0        0        1        0  \n",
       "4           1           1        0        1        0        0  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# One Hot Encoding\n",
    "# 1. Cast to pandas categorical datatype\n",
    "# 2. get dummies\n",
    "# 3. Avoiding dummy variable trap by dropping first column for each category\n",
    "\n",
    "categories = ['Pclass', 'Sex', 'Embarked', 'is_alone', 'Title']\n",
    "\n",
    "for category in categories:\n",
    "    train_data[category] = pd.Categorical(train_data[category])\n",
    "    test_data[category] = pd.Categorical(test_data[category])\n",
    "    train_data = pd.concat([train_data, pd.get_dummies(train_data[category], prefix = category, drop_first = True)], axis = 1)\n",
    "    test_data = pd.concat([test_data, pd.get_dummies(test_data[category], prefix = category, drop_first = True)], axis = 1)\n",
    "\n",
    "# Dropping unecessary rows\n",
    "# Remember, the submissions file must contain passenger id\n",
    "\n",
    "passenger_ids = test_data['PassengerId']\n",
    "train_data = train_data.drop(['PassengerId', 'Pclass', 'Name', 'Sex', 'SibSp', 'Parch', 'Ticket', 'Cabin', 'category_age', 'category_fare', 'Embarked', 'is_alone', 'Title'], axis = 1)\n",
    "test_data = test_data.drop(['PassengerId', 'Pclass', 'Name', 'Sex', 'SibSp', 'Parch', 'Ticket', 'Cabin', 'Embarked', 'is_alone', 'Title'], axis = 1)\n",
    "train_data.head()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Fare</th>\n",
       "      <th>family_size</th>\n",
       "      <th>Pclass_2</th>\n",
       "      <th>Pclass_3</th>\n",
       "      <th>Sex_1</th>\n",
       "      <th>Embarked_1</th>\n",
       "      <th>Embarked_2</th>\n",
       "      <th>is_alone_1</th>\n",
       "      <th>Title_1</th>\n",
       "      <th>Title_2</th>\n",
       "      <th>Title_3</th>\n",
       "      <th>Title_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>34</td>\n",
       "      <td>7.8292</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>47</td>\n",
       "      <td>7.0000</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>62</td>\n",
       "      <td>9.6875</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>27</td>\n",
       "      <td>8.6625</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>22</td>\n",
       "      <td>12.2875</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age     Fare  family_size  Pclass_2  Pclass_3  Sex_1  Embarked_1  \\\n",
       "0   34   7.8292            1         0         1      1           1   \n",
       "1   47   7.0000            2         0         1      0           0   \n",
       "2   62   9.6875            1         1         0      1           1   \n",
       "3   27   8.6625            1         0         1      1           0   \n",
       "4   22  12.2875            3         0         1      0           0   \n",
       "\n",
       "   Embarked_2  is_alone_1  Title_1  Title_2  Title_3  Title_4  \n",
       "0           0           1        0        1        0        0  \n",
       "1           1           0        0        0        1        0  \n",
       "2           0           1        0        1        0        0  \n",
       "3           1           1        0        1        0        0  \n",
       "4           1           0        0        0        1        0  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into train and test sets\n",
    "\n",
    "X_train = train_data.drop(['Survived'], axis = 1)\n",
    "y_train = train_data[\"Survived\"]\n",
    "X_test = test_data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 120 candidates, totalling 360 fits\n",
      "[CV] criterion=gini, min_samples_leaf=1, min_samples_split=2, n_estimators=30 \n",
      "[CV]  criterion=gini, min_samples_leaf=1, min_samples_split=2, n_estimators=30, score=0.7542087542087542, total=   0.0s\n",
      "[CV] criterion=gini, min_samples_leaf=1, min_samples_split=2, n_estimators=30 \n",
      "[CV]  criterion=gini, min_samples_leaf=1, min_samples_split=2, n_estimators=30, score=0.797979797979798, total=   0.0s\n",
      "[CV] criterion=gini, min_samples_leaf=1, min_samples_split=2, n_estimators=30 \n",
      "[CV]  criterion=gini, min_samples_leaf=1, min_samples_split=2, n_estimators=30, score=0.8013468013468014, total=   0.0s\n",
      "[CV] criterion=gini, min_samples_leaf=1, min_samples_split=2, n_estimators=50 \n",
      "[CV]  criterion=gini, min_samples_leaf=1, min_samples_split=2, n_estimators=50, score=0.7609427609427609, total=   0.1s\n",
      "[CV] criterion=gini, min_samples_leaf=1, min_samples_split=2, n_estimators=50 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.1s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  criterion=gini, min_samples_leaf=1, min_samples_split=2, n_estimators=50, score=0.8114478114478114, total=   0.1s\n",
      "[CV] criterion=gini, min_samples_leaf=1, min_samples_split=2, n_estimators=50 \n",
      "[CV]  criterion=gini, min_samples_leaf=1, min_samples_split=2, n_estimators=50, score=0.8181818181818182, total=   0.1s\n",
      "[CV] criterion=gini, min_samples_leaf=1, min_samples_split=2, n_estimators=100 \n",
      "[CV]  criterion=gini, min_samples_leaf=1, min_samples_split=2, n_estimators=100, score=0.7542087542087542, total=   0.1s\n",
      "[CV] criterion=gini, min_samples_leaf=1, min_samples_split=2, n_estimators=100 \n",
      "[CV]  criterion=gini, min_samples_leaf=1, min_samples_split=2, n_estimators=100, score=0.797979797979798, total=   0.1s\n",
      "[CV] criterion=gini, min_samples_leaf=1, min_samples_split=2, n_estimators=100 \n",
      "[CV]  criterion=gini, min_samples_leaf=1, min_samples_split=2, n_estimators=100, score=0.8080808080808081, total=   0.1s\n",
      "[CV] criterion=gini, min_samples_leaf=1, min_samples_split=2, n_estimators=200 \n",
      "[CV]  criterion=gini, min_samples_leaf=1, min_samples_split=2, n_estimators=200, score=0.7575757575757576, total=   0.2s\n",
      "[CV] criterion=gini, min_samples_leaf=1, min_samples_split=2, n_estimators=200 \n",
      "[CV]  criterion=gini, min_samples_leaf=1, min_samples_split=2, n_estimators=200, score=0.8047138047138047, total=   0.2s\n",
      "[CV] criterion=gini, min_samples_leaf=1, min_samples_split=2, n_estimators=200 \n",
      "[CV]  criterion=gini, min_samples_leaf=1, min_samples_split=2, n_estimators=200, score=0.8080808080808081, total=   0.2s\n",
      "[CV] criterion=gini, min_samples_leaf=1, min_samples_split=2, n_estimators=500 \n",
      "[CV]  criterion=gini, min_samples_leaf=1, min_samples_split=2, n_estimators=500, score=0.7474747474747475, total=   0.6s\n",
      "[CV] criterion=gini, min_samples_leaf=1, min_samples_split=2, n_estimators=500 \n",
      "[CV]  criterion=gini, min_samples_leaf=1, min_samples_split=2, n_estimators=500, score=0.8047138047138047, total=   0.6s\n",
      "[CV] criterion=gini, min_samples_leaf=1, min_samples_split=2, n_estimators=500 \n",
      "[CV]  criterion=gini, min_samples_leaf=1, min_samples_split=2, n_estimators=500, score=0.797979797979798, total=   0.6s\n",
      "[CV] criterion=gini, min_samples_leaf=1, min_samples_split=4, n_estimators=30 \n",
      "[CV]  criterion=gini, min_samples_leaf=1, min_samples_split=4, n_estimators=30, score=0.7777777777777778, total=   0.0s\n",
      "[CV] criterion=gini, min_samples_leaf=1, min_samples_split=4, n_estimators=30 \n",
      "[CV]  criterion=gini, min_samples_leaf=1, min_samples_split=4, n_estimators=30, score=0.8148148148148148, total=   0.0s\n",
      "[CV] criterion=gini, min_samples_leaf=1, min_samples_split=4, n_estimators=30 \n",
      "[CV]  criterion=gini, min_samples_leaf=1, min_samples_split=4, n_estimators=30, score=0.835016835016835, total=   0.0s\n",
      "[CV] criterion=gini, min_samples_leaf=1, min_samples_split=4, n_estimators=50 \n",
      "[CV]  criterion=gini, min_samples_leaf=1, min_samples_split=4, n_estimators=50, score=0.7609427609427609, total=   0.1s\n",
      "[CV] criterion=gini, min_samples_leaf=1, min_samples_split=4, n_estimators=50 \n",
      "[CV]  criterion=gini, min_samples_leaf=1, min_samples_split=4, n_estimators=50, score=0.8249158249158249, total=   0.1s\n",
      "[CV] criterion=gini, min_samples_leaf=1, min_samples_split=4, n_estimators=50 \n",
      "[CV]  criterion=gini, min_samples_leaf=1, min_samples_split=4, n_estimators=50, score=0.8282828282828283, total=   0.1s\n",
      "[CV] criterion=gini, min_samples_leaf=1, min_samples_split=4, n_estimators=100 \n",
      "[CV]  criterion=gini, min_samples_leaf=1, min_samples_split=4, n_estimators=100, score=0.7744107744107744, total=   0.1s\n",
      "[CV] criterion=gini, min_samples_leaf=1, min_samples_split=4, n_estimators=100 \n",
      "[CV]  criterion=gini, min_samples_leaf=1, min_samples_split=4, n_estimators=100, score=0.8316498316498316, total=   0.1s\n",
      "[CV] criterion=gini, min_samples_leaf=1, min_samples_split=4, n_estimators=100 \n",
      "[CV]  criterion=gini, min_samples_leaf=1, min_samples_split=4, n_estimators=100, score=0.8316498316498316, total=   0.1s\n",
      "[CV] criterion=gini, min_samples_leaf=1, min_samples_split=4, n_estimators=200 \n",
      "[CV]  criterion=gini, min_samples_leaf=1, min_samples_split=4, n_estimators=200, score=0.7777777777777778, total=   0.3s\n",
      "[CV] criterion=gini, min_samples_leaf=1, min_samples_split=4, n_estimators=200 \n",
      "[CV]  criterion=gini, min_samples_leaf=1, min_samples_split=4, n_estimators=200, score=0.8249158249158249, total=   0.2s\n",
      "[CV] criterion=gini, min_samples_leaf=1, min_samples_split=4, n_estimators=200 \n",
      "[CV]  criterion=gini, min_samples_leaf=1, min_samples_split=4, n_estimators=200, score=0.8282828282828283, total=   0.3s\n",
      "[CV] criterion=gini, min_samples_leaf=1, min_samples_split=4, n_estimators=500 \n",
      "[CV]  criterion=gini, min_samples_leaf=1, min_samples_split=4, n_estimators=500, score=0.7744107744107744, total=   0.6s\n",
      "[CV] criterion=gini, min_samples_leaf=1, min_samples_split=4, n_estimators=500 \n",
      "[CV]  criterion=gini, min_samples_leaf=1, min_samples_split=4, n_estimators=500, score=0.8316498316498316, total=   0.6s\n",
      "[CV] criterion=gini, min_samples_leaf=1, min_samples_split=4, n_estimators=500 \n",
      "[CV]  criterion=gini, min_samples_leaf=1, min_samples_split=4, n_estimators=500, score=0.8114478114478114, total=   0.7s\n",
      "[CV] criterion=gini, min_samples_leaf=1, min_samples_split=8, n_estimators=30 \n",
      "[CV]  criterion=gini, min_samples_leaf=1, min_samples_split=8, n_estimators=30, score=0.8013468013468014, total=   0.0s\n",
      "[CV] criterion=gini, min_samples_leaf=1, min_samples_split=8, n_estimators=30 \n",
      "[CV]  criterion=gini, min_samples_leaf=1, min_samples_split=8, n_estimators=30, score=0.8451178451178452, total=   0.0s\n",
      "[CV] criterion=gini, min_samples_leaf=1, min_samples_split=8, n_estimators=30 \n",
      "[CV]  criterion=gini, min_samples_leaf=1, min_samples_split=8, n_estimators=30, score=0.8383838383838383, total=   0.0s\n",
      "[CV] criterion=gini, min_samples_leaf=1, min_samples_split=8, n_estimators=50 \n",
      "[CV]  criterion=gini, min_samples_leaf=1, min_samples_split=8, n_estimators=50, score=0.7777777777777778, total=   0.1s\n",
      "[CV] criterion=gini, min_samples_leaf=1, min_samples_split=8, n_estimators=50 \n",
      "[CV]  criterion=gini, min_samples_leaf=1, min_samples_split=8, n_estimators=50, score=0.8484848484848485, total=   0.1s\n",
      "[CV] criterion=gini, min_samples_leaf=1, min_samples_split=8, n_estimators=50 \n",
      "[CV]  criterion=gini, min_samples_leaf=1, min_samples_split=8, n_estimators=50, score=0.8383838383838383, total=   0.1s\n",
      "[CV] criterion=gini, min_samples_leaf=1, min_samples_split=8, n_estimators=100 \n",
      "[CV]  criterion=gini, min_samples_leaf=1, min_samples_split=8, n_estimators=100, score=0.7777777777777778, total=   0.1s\n",
      "[CV] criterion=gini, min_samples_leaf=1, min_samples_split=8, n_estimators=100 \n",
      "[CV]  criterion=gini, min_samples_leaf=1, min_samples_split=8, n_estimators=100, score=0.8451178451178452, total=   0.1s\n",
      "[CV] criterion=gini, min_samples_leaf=1, min_samples_split=8, n_estimators=100 \n",
      "[CV]  criterion=gini, min_samples_leaf=1, min_samples_split=8, n_estimators=100, score=0.8451178451178452, total=   0.1s\n",
      "[CV] criterion=gini, min_samples_leaf=1, min_samples_split=8, n_estimators=200 \n",
      "[CV]  criterion=gini, min_samples_leaf=1, min_samples_split=8, n_estimators=200, score=0.8047138047138047, total=   0.2s\n",
      "[CV] criterion=gini, min_samples_leaf=1, min_samples_split=8, n_estimators=200 \n",
      "[CV]  criterion=gini, min_samples_leaf=1, min_samples_split=8, n_estimators=200, score=0.8552188552188552, total=   0.3s\n",
      "[CV] criterion=gini, min_samples_leaf=1, min_samples_split=8, n_estimators=200 \n",
      "[CV]  criterion=gini, min_samples_leaf=1, min_samples_split=8, n_estimators=200, score=0.8417508417508418, total=   0.3s\n",
      "[CV] criterion=gini, min_samples_leaf=1, min_samples_split=8, n_estimators=500 \n",
      "[CV]  criterion=gini, min_samples_leaf=1, min_samples_split=8, n_estimators=500, score=0.7946127946127947, total=   0.6s\n",
      "[CV] criterion=gini, min_samples_leaf=1, min_samples_split=8, n_estimators=500 \n",
      "[CV]  criterion=gini, min_samples_leaf=1, min_samples_split=8, n_estimators=500, score=0.8552188552188552, total=   0.6s\n",
      "[CV] criterion=gini, min_samples_leaf=1, min_samples_split=8, n_estimators=500 \n",
      "[CV]  criterion=gini, min_samples_leaf=1, min_samples_split=8, n_estimators=500, score=0.8383838383838383, total=   0.6s\n",
      "[CV] criterion=gini, min_samples_leaf=1, min_samples_split=10, n_estimators=30 \n",
      "[CV]  criterion=gini, min_samples_leaf=1, min_samples_split=10, n_estimators=30, score=0.7912457912457912, total=   0.1s\n",
      "[CV] criterion=gini, min_samples_leaf=1, min_samples_split=10, n_estimators=30 \n",
      "[CV]  criterion=gini, min_samples_leaf=1, min_samples_split=10, n_estimators=30, score=0.8552188552188552, total=   0.0s\n",
      "[CV] criterion=gini, min_samples_leaf=1, min_samples_split=10, n_estimators=30 \n",
      "[CV]  criterion=gini, min_samples_leaf=1, min_samples_split=10, n_estimators=30, score=0.8249158249158249, total=   0.0s\n",
      "[CV] criterion=gini, min_samples_leaf=1, min_samples_split=10, n_estimators=50 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  criterion=gini, min_samples_leaf=1, min_samples_split=10, n_estimators=50, score=0.8047138047138047, total=   0.1s\n",
      "[CV] criterion=gini, min_samples_leaf=1, min_samples_split=10, n_estimators=50 \n",
      "[CV]  criterion=gini, min_samples_leaf=1, min_samples_split=10, n_estimators=50, score=0.8518518518518519, total=   0.1s\n",
      "[CV] criterion=gini, min_samples_leaf=1, min_samples_split=10, n_estimators=50 \n",
      "[CV]  criterion=gini, min_samples_leaf=1, min_samples_split=10, n_estimators=50, score=0.835016835016835, total=   0.1s\n",
      "[CV] criterion=gini, min_samples_leaf=1, min_samples_split=10, n_estimators=100 \n",
      "[CV]  criterion=gini, min_samples_leaf=1, min_samples_split=10, n_estimators=100, score=0.8080808080808081, total=   0.1s\n",
      "[CV] criterion=gini, min_samples_leaf=1, min_samples_split=10, n_estimators=100 \n",
      "[CV]  criterion=gini, min_samples_leaf=1, min_samples_split=10, n_estimators=100, score=0.8686868686868687, total=   0.1s\n",
      "[CV] criterion=gini, min_samples_leaf=1, min_samples_split=10, n_estimators=100 \n",
      "[CV]  criterion=gini, min_samples_leaf=1, min_samples_split=10, n_estimators=100, score=0.8417508417508418, total=   0.1s\n",
      "[CV] criterion=gini, min_samples_leaf=1, min_samples_split=10, n_estimators=200 \n",
      "[CV]  criterion=gini, min_samples_leaf=1, min_samples_split=10, n_estimators=200, score=0.8047138047138047, total=   0.2s\n",
      "[CV] criterion=gini, min_samples_leaf=1, min_samples_split=10, n_estimators=200 \n",
      "[CV]  criterion=gini, min_samples_leaf=1, min_samples_split=10, n_estimators=200, score=0.8619528619528619, total=   0.3s\n",
      "[CV] criterion=gini, min_samples_leaf=1, min_samples_split=10, n_estimators=200 \n",
      "[CV]  criterion=gini, min_samples_leaf=1, min_samples_split=10, n_estimators=200, score=0.835016835016835, total=   0.2s\n",
      "[CV] criterion=gini, min_samples_leaf=1, min_samples_split=10, n_estimators=500 \n",
      "[CV]  criterion=gini, min_samples_leaf=1, min_samples_split=10, n_estimators=500, score=0.8114478114478114, total=   0.6s\n",
      "[CV] criterion=gini, min_samples_leaf=1, min_samples_split=10, n_estimators=500 \n",
      "[CV]  criterion=gini, min_samples_leaf=1, min_samples_split=10, n_estimators=500, score=0.8585858585858586, total=   0.6s\n",
      "[CV] criterion=gini, min_samples_leaf=1, min_samples_split=10, n_estimators=500 \n",
      "[CV]  criterion=gini, min_samples_leaf=1, min_samples_split=10, n_estimators=500, score=0.8383838383838383, total=   0.6s\n",
      "[CV] criterion=gini, min_samples_leaf=5, min_samples_split=2, n_estimators=30 \n",
      "[CV]  criterion=gini, min_samples_leaf=5, min_samples_split=2, n_estimators=30, score=0.8215488215488216, total=   0.0s\n",
      "[CV] criterion=gini, min_samples_leaf=5, min_samples_split=2, n_estimators=30 \n",
      "[CV]  criterion=gini, min_samples_leaf=5, min_samples_split=2, n_estimators=30, score=0.835016835016835, total=   0.0s\n",
      "[CV] criterion=gini, min_samples_leaf=5, min_samples_split=2, n_estimators=30 \n",
      "[CV]  criterion=gini, min_samples_leaf=5, min_samples_split=2, n_estimators=30, score=0.8249158249158249, total=   0.0s\n",
      "[CV] criterion=gini, min_samples_leaf=5, min_samples_split=2, n_estimators=50 \n",
      "[CV]  criterion=gini, min_samples_leaf=5, min_samples_split=2, n_estimators=50, score=0.8080808080808081, total=   0.1s\n",
      "[CV] criterion=gini, min_samples_leaf=5, min_samples_split=2, n_estimators=50 \n",
      "[CV]  criterion=gini, min_samples_leaf=5, min_samples_split=2, n_estimators=50, score=0.8484848484848485, total=   0.1s\n",
      "[CV] criterion=gini, min_samples_leaf=5, min_samples_split=2, n_estimators=50 \n",
      "[CV]  criterion=gini, min_samples_leaf=5, min_samples_split=2, n_estimators=50, score=0.8181818181818182, total=   0.1s\n",
      "[CV] criterion=gini, min_samples_leaf=5, min_samples_split=2, n_estimators=100 \n",
      "[CV]  criterion=gini, min_samples_leaf=5, min_samples_split=2, n_estimators=100, score=0.797979797979798, total=   0.1s\n",
      "[CV] criterion=gini, min_samples_leaf=5, min_samples_split=2, n_estimators=100 \n",
      "[CV]  criterion=gini, min_samples_leaf=5, min_samples_split=2, n_estimators=100, score=0.8383838383838383, total=   0.1s\n",
      "[CV] criterion=gini, min_samples_leaf=5, min_samples_split=2, n_estimators=100 \n",
      "[CV]  criterion=gini, min_samples_leaf=5, min_samples_split=2, n_estimators=100, score=0.8148148148148148, total=   0.1s\n",
      "[CV] criterion=gini, min_samples_leaf=5, min_samples_split=2, n_estimators=200 \n",
      "[CV]  criterion=gini, min_samples_leaf=5, min_samples_split=2, n_estimators=200, score=0.8148148148148148, total=   0.2s\n",
      "[CV] criterion=gini, min_samples_leaf=5, min_samples_split=2, n_estimators=200 \n",
      "[CV]  criterion=gini, min_samples_leaf=5, min_samples_split=2, n_estimators=200, score=0.8484848484848485, total=   0.2s\n",
      "[CV] criterion=gini, min_samples_leaf=5, min_samples_split=2, n_estimators=200 \n",
      "[CV]  criterion=gini, min_samples_leaf=5, min_samples_split=2, n_estimators=200, score=0.8215488215488216, total=   0.2s\n",
      "[CV] criterion=gini, min_samples_leaf=5, min_samples_split=2, n_estimators=500 \n",
      "[CV]  criterion=gini, min_samples_leaf=5, min_samples_split=2, n_estimators=500, score=0.8114478114478114, total=   0.5s\n",
      "[CV] criterion=gini, min_samples_leaf=5, min_samples_split=2, n_estimators=500 \n",
      "[CV]  criterion=gini, min_samples_leaf=5, min_samples_split=2, n_estimators=500, score=0.8518518518518519, total=   0.5s\n",
      "[CV] criterion=gini, min_samples_leaf=5, min_samples_split=2, n_estimators=500 \n",
      "[CV]  criterion=gini, min_samples_leaf=5, min_samples_split=2, n_estimators=500, score=0.8215488215488216, total=   0.6s\n",
      "[CV] criterion=gini, min_samples_leaf=5, min_samples_split=4, n_estimators=30 \n",
      "[CV]  criterion=gini, min_samples_leaf=5, min_samples_split=4, n_estimators=30, score=0.8215488215488216, total=   0.0s\n",
      "[CV] criterion=gini, min_samples_leaf=5, min_samples_split=4, n_estimators=30 \n",
      "[CV]  criterion=gini, min_samples_leaf=5, min_samples_split=4, n_estimators=30, score=0.8417508417508418, total=   0.0s\n",
      "[CV] criterion=gini, min_samples_leaf=5, min_samples_split=4, n_estimators=30 \n",
      "[CV]  criterion=gini, min_samples_leaf=5, min_samples_split=4, n_estimators=30, score=0.8215488215488216, total=   0.0s\n",
      "[CV] criterion=gini, min_samples_leaf=5, min_samples_split=4, n_estimators=50 \n",
      "[CV]  criterion=gini, min_samples_leaf=5, min_samples_split=4, n_estimators=50, score=0.8181818181818182, total=   0.1s\n",
      "[CV] criterion=gini, min_samples_leaf=5, min_samples_split=4, n_estimators=50 \n",
      "[CV]  criterion=gini, min_samples_leaf=5, min_samples_split=4, n_estimators=50, score=0.835016835016835, total=   0.1s\n",
      "[CV] criterion=gini, min_samples_leaf=5, min_samples_split=4, n_estimators=50 \n",
      "[CV]  criterion=gini, min_samples_leaf=5, min_samples_split=4, n_estimators=50, score=0.8249158249158249, total=   0.1s\n",
      "[CV] criterion=gini, min_samples_leaf=5, min_samples_split=4, n_estimators=100 \n",
      "[CV]  criterion=gini, min_samples_leaf=5, min_samples_split=4, n_estimators=100, score=0.8114478114478114, total=   0.1s\n",
      "[CV] criterion=gini, min_samples_leaf=5, min_samples_split=4, n_estimators=100 \n",
      "[CV]  criterion=gini, min_samples_leaf=5, min_samples_split=4, n_estimators=100, score=0.8518518518518519, total=   0.1s\n",
      "[CV] criterion=gini, min_samples_leaf=5, min_samples_split=4, n_estimators=100 \n",
      "[CV]  criterion=gini, min_samples_leaf=5, min_samples_split=4, n_estimators=100, score=0.8249158249158249, total=   0.1s\n",
      "[CV] criterion=gini, min_samples_leaf=5, min_samples_split=4, n_estimators=200 \n",
      "[CV]  criterion=gini, min_samples_leaf=5, min_samples_split=4, n_estimators=200, score=0.8114478114478114, total=   0.2s\n",
      "[CV] criterion=gini, min_samples_leaf=5, min_samples_split=4, n_estimators=200 \n",
      "[CV]  criterion=gini, min_samples_leaf=5, min_samples_split=4, n_estimators=200, score=0.8518518518518519, total=   0.2s\n",
      "[CV] criterion=gini, min_samples_leaf=5, min_samples_split=4, n_estimators=200 \n",
      "[CV]  criterion=gini, min_samples_leaf=5, min_samples_split=4, n_estimators=200, score=0.8282828282828283, total=   0.2s\n",
      "[CV] criterion=gini, min_samples_leaf=5, min_samples_split=4, n_estimators=500 \n",
      "[CV]  criterion=gini, min_samples_leaf=5, min_samples_split=4, n_estimators=500, score=0.8114478114478114, total=   0.5s\n",
      "[CV] criterion=gini, min_samples_leaf=5, min_samples_split=4, n_estimators=500 \n",
      "[CV]  criterion=gini, min_samples_leaf=5, min_samples_split=4, n_estimators=500, score=0.8518518518518519, total=   0.5s\n",
      "[CV] criterion=gini, min_samples_leaf=5, min_samples_split=4, n_estimators=500 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  criterion=gini, min_samples_leaf=5, min_samples_split=4, n_estimators=500, score=0.8249158249158249, total=   0.5s\n",
      "[CV] criterion=gini, min_samples_leaf=5, min_samples_split=8, n_estimators=30 \n",
      "[CV]  criterion=gini, min_samples_leaf=5, min_samples_split=8, n_estimators=30, score=0.7912457912457912, total=   0.0s\n",
      "[CV] criterion=gini, min_samples_leaf=5, min_samples_split=8, n_estimators=30 \n",
      "[CV]  criterion=gini, min_samples_leaf=5, min_samples_split=8, n_estimators=30, score=0.8451178451178452, total=   0.0s\n",
      "[CV] criterion=gini, min_samples_leaf=5, min_samples_split=8, n_estimators=30 \n",
      "[CV]  criterion=gini, min_samples_leaf=5, min_samples_split=8, n_estimators=30, score=0.8181818181818182, total=   0.0s\n",
      "[CV] criterion=gini, min_samples_leaf=5, min_samples_split=8, n_estimators=50 \n",
      "[CV]  criterion=gini, min_samples_leaf=5, min_samples_split=8, n_estimators=50, score=0.8080808080808081, total=   0.1s\n",
      "[CV] criterion=gini, min_samples_leaf=5, min_samples_split=8, n_estimators=50 \n",
      "[CV]  criterion=gini, min_samples_leaf=5, min_samples_split=8, n_estimators=50, score=0.8484848484848485, total=   0.1s\n",
      "[CV] criterion=gini, min_samples_leaf=5, min_samples_split=8, n_estimators=50 \n",
      "[CV]  criterion=gini, min_samples_leaf=5, min_samples_split=8, n_estimators=50, score=0.8080808080808081, total=   0.1s\n",
      "[CV] criterion=gini, min_samples_leaf=5, min_samples_split=8, n_estimators=100 \n",
      "[CV]  criterion=gini, min_samples_leaf=5, min_samples_split=8, n_estimators=100, score=0.8114478114478114, total=   0.1s\n",
      "[CV] criterion=gini, min_samples_leaf=5, min_samples_split=8, n_estimators=100 \n",
      "[CV]  criterion=gini, min_samples_leaf=5, min_samples_split=8, n_estimators=100, score=0.8417508417508418, total=   0.1s\n",
      "[CV] criterion=gini, min_samples_leaf=5, min_samples_split=8, n_estimators=100 \n",
      "[CV]  criterion=gini, min_samples_leaf=5, min_samples_split=8, n_estimators=100, score=0.8249158249158249, total=   0.1s\n",
      "[CV] criterion=gini, min_samples_leaf=5, min_samples_split=8, n_estimators=200 \n",
      "[CV]  criterion=gini, min_samples_leaf=5, min_samples_split=8, n_estimators=200, score=0.8080808080808081, total=   0.2s\n",
      "[CV] criterion=gini, min_samples_leaf=5, min_samples_split=8, n_estimators=200 \n",
      "[CV]  criterion=gini, min_samples_leaf=5, min_samples_split=8, n_estimators=200, score=0.8518518518518519, total=   0.2s\n",
      "[CV] criterion=gini, min_samples_leaf=5, min_samples_split=8, n_estimators=200 \n",
      "[CV]  criterion=gini, min_samples_leaf=5, min_samples_split=8, n_estimators=200, score=0.8249158249158249, total=   0.2s\n",
      "[CV] criterion=gini, min_samples_leaf=5, min_samples_split=8, n_estimators=500 \n",
      "[CV]  criterion=gini, min_samples_leaf=5, min_samples_split=8, n_estimators=500, score=0.8080808080808081, total=   0.6s\n",
      "[CV] criterion=gini, min_samples_leaf=5, min_samples_split=8, n_estimators=500 \n",
      "[CV]  criterion=gini, min_samples_leaf=5, min_samples_split=8, n_estimators=500, score=0.8552188552188552, total=   0.6s\n",
      "[CV] criterion=gini, min_samples_leaf=5, min_samples_split=8, n_estimators=500 \n",
      "[CV]  criterion=gini, min_samples_leaf=5, min_samples_split=8, n_estimators=500, score=0.835016835016835, total=   0.5s\n",
      "[CV] criterion=gini, min_samples_leaf=5, min_samples_split=10, n_estimators=30 \n",
      "[CV]  criterion=gini, min_samples_leaf=5, min_samples_split=10, n_estimators=30, score=0.8114478114478114, total=   0.0s\n",
      "[CV] criterion=gini, min_samples_leaf=5, min_samples_split=10, n_estimators=30 \n",
      "[CV]  criterion=gini, min_samples_leaf=5, min_samples_split=10, n_estimators=30, score=0.8417508417508418, total=   0.0s\n",
      "[CV] criterion=gini, min_samples_leaf=5, min_samples_split=10, n_estimators=30 \n",
      "[CV]  criterion=gini, min_samples_leaf=5, min_samples_split=10, n_estimators=30, score=0.8282828282828283, total=   0.0s\n",
      "[CV] criterion=gini, min_samples_leaf=5, min_samples_split=10, n_estimators=50 \n",
      "[CV]  criterion=gini, min_samples_leaf=5, min_samples_split=10, n_estimators=50, score=0.8080808080808081, total=   0.1s\n",
      "[CV] criterion=gini, min_samples_leaf=5, min_samples_split=10, n_estimators=50 \n",
      "[CV]  criterion=gini, min_samples_leaf=5, min_samples_split=10, n_estimators=50, score=0.8417508417508418, total=   0.1s\n",
      "[CV] criterion=gini, min_samples_leaf=5, min_samples_split=10, n_estimators=50 \n",
      "[CV]  criterion=gini, min_samples_leaf=5, min_samples_split=10, n_estimators=50, score=0.8249158249158249, total=   0.1s\n",
      "[CV] criterion=gini, min_samples_leaf=5, min_samples_split=10, n_estimators=100 \n",
      "[CV]  criterion=gini, min_samples_leaf=5, min_samples_split=10, n_estimators=100, score=0.8114478114478114, total=   0.1s\n",
      "[CV] criterion=gini, min_samples_leaf=5, min_samples_split=10, n_estimators=100 \n",
      "[CV]  criterion=gini, min_samples_leaf=5, min_samples_split=10, n_estimators=100, score=0.8417508417508418, total=   0.1s\n",
      "[CV] criterion=gini, min_samples_leaf=5, min_samples_split=10, n_estimators=100 \n",
      "[CV]  criterion=gini, min_samples_leaf=5, min_samples_split=10, n_estimators=100, score=0.8215488215488216, total=   0.1s\n",
      "[CV] criterion=gini, min_samples_leaf=5, min_samples_split=10, n_estimators=200 \n",
      "[CV]  criterion=gini, min_samples_leaf=5, min_samples_split=10, n_estimators=200, score=0.8114478114478114, total=   0.2s\n",
      "[CV] criterion=gini, min_samples_leaf=5, min_samples_split=10, n_estimators=200 \n",
      "[CV]  criterion=gini, min_samples_leaf=5, min_samples_split=10, n_estimators=200, score=0.8451178451178452, total=   0.2s\n",
      "[CV] criterion=gini, min_samples_leaf=5, min_samples_split=10, n_estimators=200 \n",
      "[CV]  criterion=gini, min_samples_leaf=5, min_samples_split=10, n_estimators=200, score=0.8181818181818182, total=   0.2s\n",
      "[CV] criterion=gini, min_samples_leaf=5, min_samples_split=10, n_estimators=500 \n",
      "[CV]  criterion=gini, min_samples_leaf=5, min_samples_split=10, n_estimators=500, score=0.8114478114478114, total=   0.5s\n",
      "[CV] criterion=gini, min_samples_leaf=5, min_samples_split=10, n_estimators=500 \n",
      "[CV]  criterion=gini, min_samples_leaf=5, min_samples_split=10, n_estimators=500, score=0.8484848484848485, total=   0.6s\n",
      "[CV] criterion=gini, min_samples_leaf=5, min_samples_split=10, n_estimators=500 \n",
      "[CV]  criterion=gini, min_samples_leaf=5, min_samples_split=10, n_estimators=500, score=0.8249158249158249, total=   0.6s\n",
      "[CV] criterion=gini, min_samples_leaf=10, min_samples_split=2, n_estimators=30 \n",
      "[CV]  criterion=gini, min_samples_leaf=10, min_samples_split=2, n_estimators=30, score=0.8047138047138047, total=   0.0s\n",
      "[CV] criterion=gini, min_samples_leaf=10, min_samples_split=2, n_estimators=30 \n",
      "[CV]  criterion=gini, min_samples_leaf=10, min_samples_split=2, n_estimators=30, score=0.8451178451178452, total=   0.0s\n",
      "[CV] criterion=gini, min_samples_leaf=10, min_samples_split=2, n_estimators=30 \n",
      "[CV]  criterion=gini, min_samples_leaf=10, min_samples_split=2, n_estimators=30, score=0.8047138047138047, total=   0.0s\n",
      "[CV] criterion=gini, min_samples_leaf=10, min_samples_split=2, n_estimators=50 \n",
      "[CV]  criterion=gini, min_samples_leaf=10, min_samples_split=2, n_estimators=50, score=0.8114478114478114, total=   0.1s\n",
      "[CV] criterion=gini, min_samples_leaf=10, min_samples_split=2, n_estimators=50 \n",
      "[CV]  criterion=gini, min_samples_leaf=10, min_samples_split=2, n_estimators=50, score=0.8383838383838383, total=   0.1s\n",
      "[CV] criterion=gini, min_samples_leaf=10, min_samples_split=2, n_estimators=50 \n",
      "[CV]  criterion=gini, min_samples_leaf=10, min_samples_split=2, n_estimators=50, score=0.8080808080808081, total=   0.1s\n",
      "[CV] criterion=gini, min_samples_leaf=10, min_samples_split=2, n_estimators=100 \n",
      "[CV]  criterion=gini, min_samples_leaf=10, min_samples_split=2, n_estimators=100, score=0.8080808080808081, total=   0.1s\n",
      "[CV] criterion=gini, min_samples_leaf=10, min_samples_split=2, n_estimators=100 \n",
      "[CV]  criterion=gini, min_samples_leaf=10, min_samples_split=2, n_estimators=100, score=0.8383838383838383, total=   0.1s\n",
      "[CV] criterion=gini, min_samples_leaf=10, min_samples_split=2, n_estimators=100 \n",
      "[CV]  criterion=gini, min_samples_leaf=10, min_samples_split=2, n_estimators=100, score=0.8080808080808081, total=   0.1s\n",
      "[CV] criterion=gini, min_samples_leaf=10, min_samples_split=2, n_estimators=200 \n",
      "[CV]  criterion=gini, min_samples_leaf=10, min_samples_split=2, n_estimators=200, score=0.8080808080808081, total=   0.2s\n",
      "[CV] criterion=gini, min_samples_leaf=10, min_samples_split=2, n_estimators=200 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  criterion=gini, min_samples_leaf=10, min_samples_split=2, n_estimators=200, score=0.8451178451178452, total=   0.2s\n",
      "[CV] criterion=gini, min_samples_leaf=10, min_samples_split=2, n_estimators=200 \n",
      "[CV]  criterion=gini, min_samples_leaf=10, min_samples_split=2, n_estimators=200, score=0.8047138047138047, total=   0.2s\n",
      "[CV] criterion=gini, min_samples_leaf=10, min_samples_split=2, n_estimators=500 \n",
      "[CV]  criterion=gini, min_samples_leaf=10, min_samples_split=2, n_estimators=500, score=0.8013468013468014, total=   0.5s\n",
      "[CV] criterion=gini, min_samples_leaf=10, min_samples_split=2, n_estimators=500 \n",
      "[CV]  criterion=gini, min_samples_leaf=10, min_samples_split=2, n_estimators=500, score=0.8383838383838383, total=   0.6s\n",
      "[CV] criterion=gini, min_samples_leaf=10, min_samples_split=2, n_estimators=500 \n",
      "[CV]  criterion=gini, min_samples_leaf=10, min_samples_split=2, n_estimators=500, score=0.8215488215488216, total=   0.5s\n",
      "[CV] criterion=gini, min_samples_leaf=10, min_samples_split=4, n_estimators=30 \n",
      "[CV]  criterion=gini, min_samples_leaf=10, min_samples_split=4, n_estimators=30, score=0.8114478114478114, total=   0.0s\n",
      "[CV] criterion=gini, min_samples_leaf=10, min_samples_split=4, n_estimators=30 \n",
      "[CV]  criterion=gini, min_samples_leaf=10, min_samples_split=4, n_estimators=30, score=0.835016835016835, total=   0.0s\n",
      "[CV] criterion=gini, min_samples_leaf=10, min_samples_split=4, n_estimators=30 \n",
      "[CV]  criterion=gini, min_samples_leaf=10, min_samples_split=4, n_estimators=30, score=0.8148148148148148, total=   0.0s\n",
      "[CV] criterion=gini, min_samples_leaf=10, min_samples_split=4, n_estimators=50 \n",
      "[CV]  criterion=gini, min_samples_leaf=10, min_samples_split=4, n_estimators=50, score=0.8047138047138047, total=   0.0s\n",
      "[CV] criterion=gini, min_samples_leaf=10, min_samples_split=4, n_estimators=50 \n",
      "[CV]  criterion=gini, min_samples_leaf=10, min_samples_split=4, n_estimators=50, score=0.8417508417508418, total=   0.1s\n",
      "[CV] criterion=gini, min_samples_leaf=10, min_samples_split=4, n_estimators=50 \n",
      "[CV]  criterion=gini, min_samples_leaf=10, min_samples_split=4, n_estimators=50, score=0.8013468013468014, total=   0.1s\n",
      "[CV] criterion=gini, min_samples_leaf=10, min_samples_split=4, n_estimators=100 \n",
      "[CV]  criterion=gini, min_samples_leaf=10, min_samples_split=4, n_estimators=100, score=0.7946127946127947, total=   0.1s\n",
      "[CV] criterion=gini, min_samples_leaf=10, min_samples_split=4, n_estimators=100 \n",
      "[CV]  criterion=gini, min_samples_leaf=10, min_samples_split=4, n_estimators=100, score=0.8451178451178452, total=   0.1s\n",
      "[CV] criterion=gini, min_samples_leaf=10, min_samples_split=4, n_estimators=100 \n",
      "[CV]  criterion=gini, min_samples_leaf=10, min_samples_split=4, n_estimators=100, score=0.8114478114478114, total=   0.1s\n",
      "[CV] criterion=gini, min_samples_leaf=10, min_samples_split=4, n_estimators=200 \n",
      "[CV]  criterion=gini, min_samples_leaf=10, min_samples_split=4, n_estimators=200, score=0.797979797979798, total=   0.2s\n",
      "[CV] criterion=gini, min_samples_leaf=10, min_samples_split=4, n_estimators=200 \n",
      "[CV]  criterion=gini, min_samples_leaf=10, min_samples_split=4, n_estimators=200, score=0.835016835016835, total=   0.2s\n",
      "[CV] criterion=gini, min_samples_leaf=10, min_samples_split=4, n_estimators=200 \n",
      "[CV]  criterion=gini, min_samples_leaf=10, min_samples_split=4, n_estimators=200, score=0.8013468013468014, total=   0.2s\n",
      "[CV] criterion=gini, min_samples_leaf=10, min_samples_split=4, n_estimators=500 \n",
      "[CV]  criterion=gini, min_samples_leaf=10, min_samples_split=4, n_estimators=500, score=0.8013468013468014, total=   0.5s\n",
      "[CV] criterion=gini, min_samples_leaf=10, min_samples_split=4, n_estimators=500 \n",
      "[CV]  criterion=gini, min_samples_leaf=10, min_samples_split=4, n_estimators=500, score=0.8451178451178452, total=   0.5s\n",
      "[CV] criterion=gini, min_samples_leaf=10, min_samples_split=4, n_estimators=500 \n",
      "[CV]  criterion=gini, min_samples_leaf=10, min_samples_split=4, n_estimators=500, score=0.8249158249158249, total=   0.5s\n",
      "[CV] criterion=gini, min_samples_leaf=10, min_samples_split=8, n_estimators=30 \n",
      "[CV]  criterion=gini, min_samples_leaf=10, min_samples_split=8, n_estimators=30, score=0.8080808080808081, total=   0.0s\n",
      "[CV] criterion=gini, min_samples_leaf=10, min_samples_split=8, n_estimators=30 \n",
      "[CV]  criterion=gini, min_samples_leaf=10, min_samples_split=8, n_estimators=30, score=0.8417508417508418, total=   0.0s\n",
      "[CV] criterion=gini, min_samples_leaf=10, min_samples_split=8, n_estimators=30 \n",
      "[CV]  criterion=gini, min_samples_leaf=10, min_samples_split=8, n_estimators=30, score=0.8249158249158249, total=   0.0s\n",
      "[CV] criterion=gini, min_samples_leaf=10, min_samples_split=8, n_estimators=50 \n",
      "[CV]  criterion=gini, min_samples_leaf=10, min_samples_split=8, n_estimators=50, score=0.8148148148148148, total=   0.0s\n",
      "[CV] criterion=gini, min_samples_leaf=10, min_samples_split=8, n_estimators=50 \n",
      "[CV]  criterion=gini, min_samples_leaf=10, min_samples_split=8, n_estimators=50, score=0.8383838383838383, total=   0.1s\n",
      "[CV] criterion=gini, min_samples_leaf=10, min_samples_split=8, n_estimators=50 \n",
      "[CV]  criterion=gini, min_samples_leaf=10, min_samples_split=8, n_estimators=50, score=0.797979797979798, total=   0.1s\n",
      "[CV] criterion=gini, min_samples_leaf=10, min_samples_split=8, n_estimators=100 \n",
      "[CV]  criterion=gini, min_samples_leaf=10, min_samples_split=8, n_estimators=100, score=0.8114478114478114, total=   0.1s\n",
      "[CV] criterion=gini, min_samples_leaf=10, min_samples_split=8, n_estimators=100 \n",
      "[CV]  criterion=gini, min_samples_leaf=10, min_samples_split=8, n_estimators=100, score=0.8383838383838383, total=   0.1s\n",
      "[CV] criterion=gini, min_samples_leaf=10, min_samples_split=8, n_estimators=100 \n",
      "[CV]  criterion=gini, min_samples_leaf=10, min_samples_split=8, n_estimators=100, score=0.8249158249158249, total=   0.1s\n",
      "[CV] criterion=gini, min_samples_leaf=10, min_samples_split=8, n_estimators=200 \n",
      "[CV]  criterion=gini, min_samples_leaf=10, min_samples_split=8, n_estimators=200, score=0.8080808080808081, total=   0.2s\n",
      "[CV] criterion=gini, min_samples_leaf=10, min_samples_split=8, n_estimators=200 \n",
      "[CV]  criterion=gini, min_samples_leaf=10, min_samples_split=8, n_estimators=200, score=0.8417508417508418, total=   0.2s\n",
      "[CV] criterion=gini, min_samples_leaf=10, min_samples_split=8, n_estimators=200 \n",
      "[CV]  criterion=gini, min_samples_leaf=10, min_samples_split=8, n_estimators=200, score=0.8013468013468014, total=   0.2s\n",
      "[CV] criterion=gini, min_samples_leaf=10, min_samples_split=8, n_estimators=500 \n",
      "[CV]  criterion=gini, min_samples_leaf=10, min_samples_split=8, n_estimators=500, score=0.8114478114478114, total=   0.6s\n",
      "[CV] criterion=gini, min_samples_leaf=10, min_samples_split=8, n_estimators=500 \n",
      "[CV]  criterion=gini, min_samples_leaf=10, min_samples_split=8, n_estimators=500, score=0.8383838383838383, total=   0.6s\n",
      "[CV] criterion=gini, min_samples_leaf=10, min_samples_split=8, n_estimators=500 \n",
      "[CV]  criterion=gini, min_samples_leaf=10, min_samples_split=8, n_estimators=500, score=0.8047138047138047, total=   0.6s\n",
      "[CV] criterion=gini, min_samples_leaf=10, min_samples_split=10, n_estimators=30 \n",
      "[CV]  criterion=gini, min_samples_leaf=10, min_samples_split=10, n_estimators=30, score=0.8181818181818182, total=   0.0s\n",
      "[CV] criterion=gini, min_samples_leaf=10, min_samples_split=10, n_estimators=30 \n",
      "[CV]  criterion=gini, min_samples_leaf=10, min_samples_split=10, n_estimators=30, score=0.8451178451178452, total=   0.0s\n",
      "[CV] criterion=gini, min_samples_leaf=10, min_samples_split=10, n_estimators=30 \n",
      "[CV]  criterion=gini, min_samples_leaf=10, min_samples_split=10, n_estimators=30, score=0.8013468013468014, total=   0.0s\n",
      "[CV] criterion=gini, min_samples_leaf=10, min_samples_split=10, n_estimators=50 \n",
      "[CV]  criterion=gini, min_samples_leaf=10, min_samples_split=10, n_estimators=50, score=0.8148148148148148, total=   0.1s\n",
      "[CV] criterion=gini, min_samples_leaf=10, min_samples_split=10, n_estimators=50 \n",
      "[CV]  criterion=gini, min_samples_leaf=10, min_samples_split=10, n_estimators=50, score=0.8417508417508418, total=   0.1s\n",
      "[CV] criterion=gini, min_samples_leaf=10, min_samples_split=10, n_estimators=50 \n",
      "[CV]  criterion=gini, min_samples_leaf=10, min_samples_split=10, n_estimators=50, score=0.8047138047138047, total=   0.1s\n",
      "[CV] criterion=gini, min_samples_leaf=10, min_samples_split=10, n_estimators=100 \n",
      "[CV]  criterion=gini, min_samples_leaf=10, min_samples_split=10, n_estimators=100, score=0.8080808080808081, total=   0.1s\n",
      "[CV] criterion=gini, min_samples_leaf=10, min_samples_split=10, n_estimators=100 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  criterion=gini, min_samples_leaf=10, min_samples_split=10, n_estimators=100, score=0.835016835016835, total=   0.1s\n",
      "[CV] criterion=gini, min_samples_leaf=10, min_samples_split=10, n_estimators=100 \n",
      "[CV]  criterion=gini, min_samples_leaf=10, min_samples_split=10, n_estimators=100, score=0.8080808080808081, total=   0.1s\n",
      "[CV] criterion=gini, min_samples_leaf=10, min_samples_split=10, n_estimators=200 \n",
      "[CV]  criterion=gini, min_samples_leaf=10, min_samples_split=10, n_estimators=200, score=0.8047138047138047, total=   0.2s\n",
      "[CV] criterion=gini, min_samples_leaf=10, min_samples_split=10, n_estimators=200 \n",
      "[CV]  criterion=gini, min_samples_leaf=10, min_samples_split=10, n_estimators=200, score=0.835016835016835, total=   0.2s\n",
      "[CV] criterion=gini, min_samples_leaf=10, min_samples_split=10, n_estimators=200 \n",
      "[CV]  criterion=gini, min_samples_leaf=10, min_samples_split=10, n_estimators=200, score=0.8215488215488216, total=   0.2s\n",
      "[CV] criterion=gini, min_samples_leaf=10, min_samples_split=10, n_estimators=500 \n",
      "[CV]  criterion=gini, min_samples_leaf=10, min_samples_split=10, n_estimators=500, score=0.8080808080808081, total=   0.6s\n",
      "[CV] criterion=gini, min_samples_leaf=10, min_samples_split=10, n_estimators=500 \n",
      "[CV]  criterion=gini, min_samples_leaf=10, min_samples_split=10, n_estimators=500, score=0.8417508417508418, total=   0.6s\n",
      "[CV] criterion=gini, min_samples_leaf=10, min_samples_split=10, n_estimators=500 \n",
      "[CV]  criterion=gini, min_samples_leaf=10, min_samples_split=10, n_estimators=500, score=0.8047138047138047, total=   0.6s\n",
      "[CV] criterion=entropy, min_samples_leaf=1, min_samples_split=2, n_estimators=30 \n",
      "[CV]  criterion=entropy, min_samples_leaf=1, min_samples_split=2, n_estimators=30, score=0.7744107744107744, total=   0.0s\n",
      "[CV] criterion=entropy, min_samples_leaf=1, min_samples_split=2, n_estimators=30 \n",
      "[CV]  criterion=entropy, min_samples_leaf=1, min_samples_split=2, n_estimators=30, score=0.797979797979798, total=   0.0s\n",
      "[CV] criterion=entropy, min_samples_leaf=1, min_samples_split=2, n_estimators=30 \n",
      "[CV]  criterion=entropy, min_samples_leaf=1, min_samples_split=2, n_estimators=30, score=0.8114478114478114, total=   0.0s\n",
      "[CV] criterion=entropy, min_samples_leaf=1, min_samples_split=2, n_estimators=50 \n",
      "[CV]  criterion=entropy, min_samples_leaf=1, min_samples_split=2, n_estimators=50, score=0.7676767676767676, total=   0.1s\n",
      "[CV] criterion=entropy, min_samples_leaf=1, min_samples_split=2, n_estimators=50 \n",
      "[CV]  criterion=entropy, min_samples_leaf=1, min_samples_split=2, n_estimators=50, score=0.8013468013468014, total=   0.1s\n",
      "[CV] criterion=entropy, min_samples_leaf=1, min_samples_split=2, n_estimators=50 \n",
      "[CV]  criterion=entropy, min_samples_leaf=1, min_samples_split=2, n_estimators=50, score=0.8047138047138047, total=   0.1s\n",
      "[CV] criterion=entropy, min_samples_leaf=1, min_samples_split=2, n_estimators=100 \n",
      "[CV]  criterion=entropy, min_samples_leaf=1, min_samples_split=2, n_estimators=100, score=0.7441077441077442, total=   0.1s\n",
      "[CV] criterion=entropy, min_samples_leaf=1, min_samples_split=2, n_estimators=100 \n",
      "[CV]  criterion=entropy, min_samples_leaf=1, min_samples_split=2, n_estimators=100, score=0.8080808080808081, total=   0.1s\n",
      "[CV] criterion=entropy, min_samples_leaf=1, min_samples_split=2, n_estimators=100 \n",
      "[CV]  criterion=entropy, min_samples_leaf=1, min_samples_split=2, n_estimators=100, score=0.8148148148148148, total=   0.1s\n",
      "[CV] criterion=entropy, min_samples_leaf=1, min_samples_split=2, n_estimators=200 \n",
      "[CV]  criterion=entropy, min_samples_leaf=1, min_samples_split=2, n_estimators=200, score=0.7508417508417509, total=   0.3s\n",
      "[CV] criterion=entropy, min_samples_leaf=1, min_samples_split=2, n_estimators=200 \n",
      "[CV]  criterion=entropy, min_samples_leaf=1, min_samples_split=2, n_estimators=200, score=0.8013468013468014, total=   0.2s\n",
      "[CV] criterion=entropy, min_samples_leaf=1, min_samples_split=2, n_estimators=200 \n",
      "[CV]  criterion=entropy, min_samples_leaf=1, min_samples_split=2, n_estimators=200, score=0.8148148148148148, total=   0.2s\n",
      "[CV] criterion=entropy, min_samples_leaf=1, min_samples_split=2, n_estimators=500 \n",
      "[CV]  criterion=entropy, min_samples_leaf=1, min_samples_split=2, n_estimators=500, score=0.7508417508417509, total=   0.7s\n",
      "[CV] criterion=entropy, min_samples_leaf=1, min_samples_split=2, n_estimators=500 \n",
      "[CV]  criterion=entropy, min_samples_leaf=1, min_samples_split=2, n_estimators=500, score=0.8148148148148148, total=   0.6s\n",
      "[CV] criterion=entropy, min_samples_leaf=1, min_samples_split=2, n_estimators=500 \n",
      "[CV]  criterion=entropy, min_samples_leaf=1, min_samples_split=2, n_estimators=500, score=0.8080808080808081, total=   0.7s\n",
      "[CV] criterion=entropy, min_samples_leaf=1, min_samples_split=4, n_estimators=30 \n",
      "[CV]  criterion=entropy, min_samples_leaf=1, min_samples_split=4, n_estimators=30, score=0.7676767676767676, total=   0.0s\n",
      "[CV] criterion=entropy, min_samples_leaf=1, min_samples_split=4, n_estimators=30 \n",
      "[CV]  criterion=entropy, min_samples_leaf=1, min_samples_split=4, n_estimators=30, score=0.8249158249158249, total=   0.0s\n",
      "[CV] criterion=entropy, min_samples_leaf=1, min_samples_split=4, n_estimators=30 \n",
      "[CV]  criterion=entropy, min_samples_leaf=1, min_samples_split=4, n_estimators=30, score=0.8013468013468014, total=   0.0s\n",
      "[CV] criterion=entropy, min_samples_leaf=1, min_samples_split=4, n_estimators=50 \n",
      "[CV]  criterion=entropy, min_samples_leaf=1, min_samples_split=4, n_estimators=50, score=0.7710437710437711, total=   0.1s\n",
      "[CV] criterion=entropy, min_samples_leaf=1, min_samples_split=4, n_estimators=50 \n",
      "[CV]  criterion=entropy, min_samples_leaf=1, min_samples_split=4, n_estimators=50, score=0.8383838383838383, total=   0.1s\n",
      "[CV] criterion=entropy, min_samples_leaf=1, min_samples_split=4, n_estimators=50 \n",
      "[CV]  criterion=entropy, min_samples_leaf=1, min_samples_split=4, n_estimators=50, score=0.8148148148148148, total=   0.1s\n",
      "[CV] criterion=entropy, min_samples_leaf=1, min_samples_split=4, n_estimators=100 \n",
      "[CV]  criterion=entropy, min_samples_leaf=1, min_samples_split=4, n_estimators=100, score=0.7710437710437711, total=   0.1s\n",
      "[CV] criterion=entropy, min_samples_leaf=1, min_samples_split=4, n_estimators=100 \n",
      "[CV]  criterion=entropy, min_samples_leaf=1, min_samples_split=4, n_estimators=100, score=0.8215488215488216, total=   0.1s\n",
      "[CV] criterion=entropy, min_samples_leaf=1, min_samples_split=4, n_estimators=100 \n",
      "[CV]  criterion=entropy, min_samples_leaf=1, min_samples_split=4, n_estimators=100, score=0.8181818181818182, total=   0.1s\n",
      "[CV] criterion=entropy, min_samples_leaf=1, min_samples_split=4, n_estimators=200 \n",
      "[CV]  criterion=entropy, min_samples_leaf=1, min_samples_split=4, n_estimators=200, score=0.7744107744107744, total=   0.3s\n",
      "[CV] criterion=entropy, min_samples_leaf=1, min_samples_split=4, n_estimators=200 \n",
      "[CV]  criterion=entropy, min_samples_leaf=1, min_samples_split=4, n_estimators=200, score=0.8282828282828283, total=   0.3s\n",
      "[CV] criterion=entropy, min_samples_leaf=1, min_samples_split=4, n_estimators=200 \n",
      "[CV]  criterion=entropy, min_samples_leaf=1, min_samples_split=4, n_estimators=200, score=0.8181818181818182, total=   0.3s\n",
      "[CV] criterion=entropy, min_samples_leaf=1, min_samples_split=4, n_estimators=500 \n",
      "[CV]  criterion=entropy, min_samples_leaf=1, min_samples_split=4, n_estimators=500, score=0.7744107744107744, total=   0.6s\n",
      "[CV] criterion=entropy, min_samples_leaf=1, min_samples_split=4, n_estimators=500 \n",
      "[CV]  criterion=entropy, min_samples_leaf=1, min_samples_split=4, n_estimators=500, score=0.8181818181818182, total=   0.6s\n",
      "[CV] criterion=entropy, min_samples_leaf=1, min_samples_split=4, n_estimators=500 \n",
      "[CV]  criterion=entropy, min_samples_leaf=1, min_samples_split=4, n_estimators=500, score=0.8215488215488216, total=   0.7s\n",
      "[CV] criterion=entropy, min_samples_leaf=1, min_samples_split=8, n_estimators=30 \n",
      "[CV]  criterion=entropy, min_samples_leaf=1, min_samples_split=8, n_estimators=30, score=0.7744107744107744, total=   0.0s\n",
      "[CV] criterion=entropy, min_samples_leaf=1, min_samples_split=8, n_estimators=30 \n",
      "[CV]  criterion=entropy, min_samples_leaf=1, min_samples_split=8, n_estimators=30, score=0.835016835016835, total=   0.0s\n",
      "[CV] criterion=entropy, min_samples_leaf=1, min_samples_split=8, n_estimators=30 \n",
      "[CV]  criterion=entropy, min_samples_leaf=1, min_samples_split=8, n_estimators=30, score=0.8249158249158249, total=   0.0s\n",
      "[CV] criterion=entropy, min_samples_leaf=1, min_samples_split=8, n_estimators=50 \n",
      "[CV]  criterion=entropy, min_samples_leaf=1, min_samples_split=8, n_estimators=50, score=0.7946127946127947, total=   0.1s\n",
      "[CV] criterion=entropy, min_samples_leaf=1, min_samples_split=8, n_estimators=50 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  criterion=entropy, min_samples_leaf=1, min_samples_split=8, n_estimators=50, score=0.8518518518518519, total=   0.1s\n",
      "[CV] criterion=entropy, min_samples_leaf=1, min_samples_split=8, n_estimators=50 \n",
      "[CV]  criterion=entropy, min_samples_leaf=1, min_samples_split=8, n_estimators=50, score=0.8417508417508418, total=   0.1s\n",
      "[CV] criterion=entropy, min_samples_leaf=1, min_samples_split=8, n_estimators=100 \n",
      "[CV]  criterion=entropy, min_samples_leaf=1, min_samples_split=8, n_estimators=100, score=0.8114478114478114, total=   0.1s\n",
      "[CV] criterion=entropy, min_samples_leaf=1, min_samples_split=8, n_estimators=100 \n",
      "[CV]  criterion=entropy, min_samples_leaf=1, min_samples_split=8, n_estimators=100, score=0.8619528619528619, total=   0.1s\n",
      "[CV] criterion=entropy, min_samples_leaf=1, min_samples_split=8, n_estimators=100 \n",
      "[CV]  criterion=entropy, min_samples_leaf=1, min_samples_split=8, n_estimators=100, score=0.8316498316498316, total=   0.1s\n",
      "[CV] criterion=entropy, min_samples_leaf=1, min_samples_split=8, n_estimators=200 \n",
      "[CV]  criterion=entropy, min_samples_leaf=1, min_samples_split=8, n_estimators=200, score=0.8047138047138047, total=   0.3s\n",
      "[CV] criterion=entropy, min_samples_leaf=1, min_samples_split=8, n_estimators=200 \n",
      "[CV]  criterion=entropy, min_samples_leaf=1, min_samples_split=8, n_estimators=200, score=0.8585858585858586, total=   0.3s\n",
      "[CV] criterion=entropy, min_samples_leaf=1, min_samples_split=8, n_estimators=200 \n",
      "[CV]  criterion=entropy, min_samples_leaf=1, min_samples_split=8, n_estimators=200, score=0.8282828282828283, total=   0.2s\n",
      "[CV] criterion=entropy, min_samples_leaf=1, min_samples_split=8, n_estimators=500 \n",
      "[CV]  criterion=entropy, min_samples_leaf=1, min_samples_split=8, n_estimators=500, score=0.7878787878787878, total=   0.7s\n",
      "[CV] criterion=entropy, min_samples_leaf=1, min_samples_split=8, n_estimators=500 \n",
      "[CV]  criterion=entropy, min_samples_leaf=1, min_samples_split=8, n_estimators=500, score=0.8518518518518519, total=   0.6s\n",
      "[CV] criterion=entropy, min_samples_leaf=1, min_samples_split=8, n_estimators=500 \n",
      "[CV]  criterion=entropy, min_samples_leaf=1, min_samples_split=8, n_estimators=500, score=0.8451178451178452, total=   0.6s\n",
      "[CV] criterion=entropy, min_samples_leaf=1, min_samples_split=10, n_estimators=30 \n",
      "[CV]  criterion=entropy, min_samples_leaf=1, min_samples_split=10, n_estimators=30, score=0.7912457912457912, total=   0.0s\n",
      "[CV] criterion=entropy, min_samples_leaf=1, min_samples_split=10, n_estimators=30 \n",
      "[CV]  criterion=entropy, min_samples_leaf=1, min_samples_split=10, n_estimators=30, score=0.8552188552188552, total=   0.0s\n",
      "[CV] criterion=entropy, min_samples_leaf=1, min_samples_split=10, n_estimators=30 \n",
      "[CV]  criterion=entropy, min_samples_leaf=1, min_samples_split=10, n_estimators=30, score=0.8316498316498316, total=   0.0s\n",
      "[CV] criterion=entropy, min_samples_leaf=1, min_samples_split=10, n_estimators=50 \n",
      "[CV]  criterion=entropy, min_samples_leaf=1, min_samples_split=10, n_estimators=50, score=0.8114478114478114, total=   0.1s\n",
      "[CV] criterion=entropy, min_samples_leaf=1, min_samples_split=10, n_estimators=50 \n",
      "[CV]  criterion=entropy, min_samples_leaf=1, min_samples_split=10, n_estimators=50, score=0.8552188552188552, total=   0.1s\n",
      "[CV] criterion=entropy, min_samples_leaf=1, min_samples_split=10, n_estimators=50 \n",
      "[CV]  criterion=entropy, min_samples_leaf=1, min_samples_split=10, n_estimators=50, score=0.8383838383838383, total=   0.1s\n",
      "[CV] criterion=entropy, min_samples_leaf=1, min_samples_split=10, n_estimators=100 \n",
      "[CV]  criterion=entropy, min_samples_leaf=1, min_samples_split=10, n_estimators=100, score=0.797979797979798, total=   0.1s\n",
      "[CV] criterion=entropy, min_samples_leaf=1, min_samples_split=10, n_estimators=100 \n",
      "[CV]  criterion=entropy, min_samples_leaf=1, min_samples_split=10, n_estimators=100, score=0.8585858585858586, total=   0.1s\n",
      "[CV] criterion=entropy, min_samples_leaf=1, min_samples_split=10, n_estimators=100 \n",
      "[CV]  criterion=entropy, min_samples_leaf=1, min_samples_split=10, n_estimators=100, score=0.8316498316498316, total=   0.1s\n",
      "[CV] criterion=entropy, min_samples_leaf=1, min_samples_split=10, n_estimators=200 \n",
      "[CV]  criterion=entropy, min_samples_leaf=1, min_samples_split=10, n_estimators=200, score=0.8114478114478114, total=   0.3s\n",
      "[CV] criterion=entropy, min_samples_leaf=1, min_samples_split=10, n_estimators=200 \n",
      "[CV]  criterion=entropy, min_samples_leaf=1, min_samples_split=10, n_estimators=200, score=0.8518518518518519, total=   0.3s\n",
      "[CV] criterion=entropy, min_samples_leaf=1, min_samples_split=10, n_estimators=200 \n",
      "[CV]  criterion=entropy, min_samples_leaf=1, min_samples_split=10, n_estimators=200, score=0.8282828282828283, total=   0.3s\n",
      "[CV] criterion=entropy, min_samples_leaf=1, min_samples_split=10, n_estimators=500 \n",
      "[CV]  criterion=entropy, min_samples_leaf=1, min_samples_split=10, n_estimators=500, score=0.8114478114478114, total=   0.6s\n",
      "[CV] criterion=entropy, min_samples_leaf=1, min_samples_split=10, n_estimators=500 \n",
      "[CV]  criterion=entropy, min_samples_leaf=1, min_samples_split=10, n_estimators=500, score=0.8653198653198653, total=   0.6s\n",
      "[CV] criterion=entropy, min_samples_leaf=1, min_samples_split=10, n_estimators=500 \n",
      "[CV]  criterion=entropy, min_samples_leaf=1, min_samples_split=10, n_estimators=500, score=0.8383838383838383, total=   0.6s\n",
      "[CV] criterion=entropy, min_samples_leaf=5, min_samples_split=2, n_estimators=30 \n",
      "[CV]  criterion=entropy, min_samples_leaf=5, min_samples_split=2, n_estimators=30, score=0.8148148148148148, total=   0.0s\n",
      "[CV] criterion=entropy, min_samples_leaf=5, min_samples_split=2, n_estimators=30 \n",
      "[CV]  criterion=entropy, min_samples_leaf=5, min_samples_split=2, n_estimators=30, score=0.8518518518518519, total=   0.0s\n",
      "[CV] criterion=entropy, min_samples_leaf=5, min_samples_split=2, n_estimators=30 \n",
      "[CV]  criterion=entropy, min_samples_leaf=5, min_samples_split=2, n_estimators=30, score=0.8013468013468014, total=   0.0s\n",
      "[CV] criterion=entropy, min_samples_leaf=5, min_samples_split=2, n_estimators=50 \n",
      "[CV]  criterion=entropy, min_samples_leaf=5, min_samples_split=2, n_estimators=50, score=0.8013468013468014, total=   0.1s\n",
      "[CV] criterion=entropy, min_samples_leaf=5, min_samples_split=2, n_estimators=50 \n",
      "[CV]  criterion=entropy, min_samples_leaf=5, min_samples_split=2, n_estimators=50, score=0.8686868686868687, total=   0.1s\n",
      "[CV] criterion=entropy, min_samples_leaf=5, min_samples_split=2, n_estimators=50 \n",
      "[CV]  criterion=entropy, min_samples_leaf=5, min_samples_split=2, n_estimators=50, score=0.8249158249158249, total=   0.1s\n",
      "[CV] criterion=entropy, min_samples_leaf=5, min_samples_split=2, n_estimators=100 \n",
      "[CV]  criterion=entropy, min_samples_leaf=5, min_samples_split=2, n_estimators=100, score=0.8114478114478114, total=   0.1s\n",
      "[CV] criterion=entropy, min_samples_leaf=5, min_samples_split=2, n_estimators=100 \n",
      "[CV]  criterion=entropy, min_samples_leaf=5, min_samples_split=2, n_estimators=100, score=0.8552188552188552, total=   0.1s\n",
      "[CV] criterion=entropy, min_samples_leaf=5, min_samples_split=2, n_estimators=100 \n",
      "[CV]  criterion=entropy, min_samples_leaf=5, min_samples_split=2, n_estimators=100, score=0.8181818181818182, total=   0.1s\n",
      "[CV] criterion=entropy, min_samples_leaf=5, min_samples_split=2, n_estimators=200 \n",
      "[CV]  criterion=entropy, min_samples_leaf=5, min_samples_split=2, n_estimators=200, score=0.8114478114478114, total=   0.2s\n",
      "[CV] criterion=entropy, min_samples_leaf=5, min_samples_split=2, n_estimators=200 \n",
      "[CV]  criterion=entropy, min_samples_leaf=5, min_samples_split=2, n_estimators=200, score=0.8417508417508418, total=   0.2s\n",
      "[CV] criterion=entropy, min_samples_leaf=5, min_samples_split=2, n_estimators=200 \n",
      "[CV]  criterion=entropy, min_samples_leaf=5, min_samples_split=2, n_estimators=200, score=0.8316498316498316, total=   0.2s\n",
      "[CV] criterion=entropy, min_samples_leaf=5, min_samples_split=2, n_estimators=500 \n",
      "[CV]  criterion=entropy, min_samples_leaf=5, min_samples_split=2, n_estimators=500, score=0.8181818181818182, total=   0.6s\n",
      "[CV] criterion=entropy, min_samples_leaf=5, min_samples_split=2, n_estimators=500 \n",
      "[CV]  criterion=entropy, min_samples_leaf=5, min_samples_split=2, n_estimators=500, score=0.8518518518518519, total=   0.5s\n",
      "[CV] criterion=entropy, min_samples_leaf=5, min_samples_split=2, n_estimators=500 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  criterion=entropy, min_samples_leaf=5, min_samples_split=2, n_estimators=500, score=0.8181818181818182, total=   0.5s\n",
      "[CV] criterion=entropy, min_samples_leaf=5, min_samples_split=4, n_estimators=30 \n",
      "[CV]  criterion=entropy, min_samples_leaf=5, min_samples_split=4, n_estimators=30, score=0.8114478114478114, total=   0.0s\n",
      "[CV] criterion=entropy, min_samples_leaf=5, min_samples_split=4, n_estimators=30 \n",
      "[CV]  criterion=entropy, min_samples_leaf=5, min_samples_split=4, n_estimators=30, score=0.8316498316498316, total=   0.0s\n",
      "[CV] criterion=entropy, min_samples_leaf=5, min_samples_split=4, n_estimators=30 \n",
      "[CV]  criterion=entropy, min_samples_leaf=5, min_samples_split=4, n_estimators=30, score=0.835016835016835, total=   0.1s\n",
      "[CV] criterion=entropy, min_samples_leaf=5, min_samples_split=4, n_estimators=50 \n",
      "[CV]  criterion=entropy, min_samples_leaf=5, min_samples_split=4, n_estimators=50, score=0.8114478114478114, total=   0.1s\n",
      "[CV] criterion=entropy, min_samples_leaf=5, min_samples_split=4, n_estimators=50 \n",
      "[CV]  criterion=entropy, min_samples_leaf=5, min_samples_split=4, n_estimators=50, score=0.8417508417508418, total=   0.1s\n",
      "[CV] criterion=entropy, min_samples_leaf=5, min_samples_split=4, n_estimators=50 \n",
      "[CV]  criterion=entropy, min_samples_leaf=5, min_samples_split=4, n_estimators=50, score=0.8181818181818182, total=   0.1s\n",
      "[CV] criterion=entropy, min_samples_leaf=5, min_samples_split=4, n_estimators=100 \n",
      "[CV]  criterion=entropy, min_samples_leaf=5, min_samples_split=4, n_estimators=100, score=0.8181818181818182, total=   0.1s\n",
      "[CV] criterion=entropy, min_samples_leaf=5, min_samples_split=4, n_estimators=100 \n",
      "[CV]  criterion=entropy, min_samples_leaf=5, min_samples_split=4, n_estimators=100, score=0.8518518518518519, total=   0.1s\n",
      "[CV] criterion=entropy, min_samples_leaf=5, min_samples_split=4, n_estimators=100 \n",
      "[CV]  criterion=entropy, min_samples_leaf=5, min_samples_split=4, n_estimators=100, score=0.835016835016835, total=   0.1s\n",
      "[CV] criterion=entropy, min_samples_leaf=5, min_samples_split=4, n_estimators=200 \n",
      "[CV]  criterion=entropy, min_samples_leaf=5, min_samples_split=4, n_estimators=200, score=0.8181818181818182, total=   0.3s\n",
      "[CV] criterion=entropy, min_samples_leaf=5, min_samples_split=4, n_estimators=200 \n",
      "[CV]  criterion=entropy, min_samples_leaf=5, min_samples_split=4, n_estimators=200, score=0.8552188552188552, total=   0.3s\n",
      "[CV] criterion=entropy, min_samples_leaf=5, min_samples_split=4, n_estimators=200 \n",
      "[CV]  criterion=entropy, min_samples_leaf=5, min_samples_split=4, n_estimators=200, score=0.8215488215488216, total=   0.2s\n",
      "[CV] criterion=entropy, min_samples_leaf=5, min_samples_split=4, n_estimators=500 \n",
      "[CV]  criterion=entropy, min_samples_leaf=5, min_samples_split=4, n_estimators=500, score=0.8215488215488216, total=   0.6s\n",
      "[CV] criterion=entropy, min_samples_leaf=5, min_samples_split=4, n_estimators=500 \n",
      "[CV]  criterion=entropy, min_samples_leaf=5, min_samples_split=4, n_estimators=500, score=0.8484848484848485, total=   0.5s\n",
      "[CV] criterion=entropy, min_samples_leaf=5, min_samples_split=4, n_estimators=500 \n",
      "[CV]  criterion=entropy, min_samples_leaf=5, min_samples_split=4, n_estimators=500, score=0.8215488215488216, total=   0.6s\n",
      "[CV] criterion=entropy, min_samples_leaf=5, min_samples_split=8, n_estimators=30 \n",
      "[CV]  criterion=entropy, min_samples_leaf=5, min_samples_split=8, n_estimators=30, score=0.8114478114478114, total=   0.0s\n",
      "[CV] criterion=entropy, min_samples_leaf=5, min_samples_split=8, n_estimators=30 \n",
      "[CV]  criterion=entropy, min_samples_leaf=5, min_samples_split=8, n_estimators=30, score=0.8383838383838383, total=   0.1s\n",
      "[CV] criterion=entropy, min_samples_leaf=5, min_samples_split=8, n_estimators=30 \n",
      "[CV]  criterion=entropy, min_samples_leaf=5, min_samples_split=8, n_estimators=30, score=0.8080808080808081, total=   0.0s\n",
      "[CV] criterion=entropy, min_samples_leaf=5, min_samples_split=8, n_estimators=50 \n",
      "[CV]  criterion=entropy, min_samples_leaf=5, min_samples_split=8, n_estimators=50, score=0.8148148148148148, total=   0.1s\n",
      "[CV] criterion=entropy, min_samples_leaf=5, min_samples_split=8, n_estimators=50 \n",
      "[CV]  criterion=entropy, min_samples_leaf=5, min_samples_split=8, n_estimators=50, score=0.8484848484848485, total=   0.1s\n",
      "[CV] criterion=entropy, min_samples_leaf=5, min_samples_split=8, n_estimators=50 \n",
      "[CV]  criterion=entropy, min_samples_leaf=5, min_samples_split=8, n_estimators=50, score=0.8282828282828283, total=   0.1s\n",
      "[CV] criterion=entropy, min_samples_leaf=5, min_samples_split=8, n_estimators=100 \n",
      "[CV]  criterion=entropy, min_samples_leaf=5, min_samples_split=8, n_estimators=100, score=0.8080808080808081, total=   0.1s\n",
      "[CV] criterion=entropy, min_samples_leaf=5, min_samples_split=8, n_estimators=100 \n",
      "[CV]  criterion=entropy, min_samples_leaf=5, min_samples_split=8, n_estimators=100, score=0.8518518518518519, total=   0.1s\n",
      "[CV] criterion=entropy, min_samples_leaf=5, min_samples_split=8, n_estimators=100 \n",
      "[CV]  criterion=entropy, min_samples_leaf=5, min_samples_split=8, n_estimators=100, score=0.835016835016835, total=   0.1s\n",
      "[CV] criterion=entropy, min_samples_leaf=5, min_samples_split=8, n_estimators=200 \n",
      "[CV]  criterion=entropy, min_samples_leaf=5, min_samples_split=8, n_estimators=200, score=0.8181818181818182, total=   0.2s\n",
      "[CV] criterion=entropy, min_samples_leaf=5, min_samples_split=8, n_estimators=200 \n",
      "[CV]  criterion=entropy, min_samples_leaf=5, min_samples_split=8, n_estimators=200, score=0.8484848484848485, total=   0.2s\n",
      "[CV] criterion=entropy, min_samples_leaf=5, min_samples_split=8, n_estimators=200 \n",
      "[CV]  criterion=entropy, min_samples_leaf=5, min_samples_split=8, n_estimators=200, score=0.8316498316498316, total=   0.2s\n",
      "[CV] criterion=entropy, min_samples_leaf=5, min_samples_split=8, n_estimators=500 \n",
      "[CV]  criterion=entropy, min_samples_leaf=5, min_samples_split=8, n_estimators=500, score=0.8080808080808081, total=   0.6s\n",
      "[CV] criterion=entropy, min_samples_leaf=5, min_samples_split=8, n_estimators=500 \n",
      "[CV]  criterion=entropy, min_samples_leaf=5, min_samples_split=8, n_estimators=500, score=0.8484848484848485, total=   0.6s\n",
      "[CV] criterion=entropy, min_samples_leaf=5, min_samples_split=8, n_estimators=500 \n",
      "[CV]  criterion=entropy, min_samples_leaf=5, min_samples_split=8, n_estimators=500, score=0.8282828282828283, total=   0.6s\n",
      "[CV] criterion=entropy, min_samples_leaf=5, min_samples_split=10, n_estimators=30 \n",
      "[CV]  criterion=entropy, min_samples_leaf=5, min_samples_split=10, n_estimators=30, score=0.8047138047138047, total=   0.0s\n",
      "[CV] criterion=entropy, min_samples_leaf=5, min_samples_split=10, n_estimators=30 \n",
      "[CV]  criterion=entropy, min_samples_leaf=5, min_samples_split=10, n_estimators=30, score=0.8484848484848485, total=   0.0s\n",
      "[CV] criterion=entropy, min_samples_leaf=5, min_samples_split=10, n_estimators=30 \n",
      "[CV]  criterion=entropy, min_samples_leaf=5, min_samples_split=10, n_estimators=30, score=0.8282828282828283, total=   0.0s\n",
      "[CV] criterion=entropy, min_samples_leaf=5, min_samples_split=10, n_estimators=50 \n",
      "[CV]  criterion=entropy, min_samples_leaf=5, min_samples_split=10, n_estimators=50, score=0.8047138047138047, total=   0.1s\n",
      "[CV] criterion=entropy, min_samples_leaf=5, min_samples_split=10, n_estimators=50 \n",
      "[CV]  criterion=entropy, min_samples_leaf=5, min_samples_split=10, n_estimators=50, score=0.8518518518518519, total=   0.1s\n",
      "[CV] criterion=entropy, min_samples_leaf=5, min_samples_split=10, n_estimators=50 \n",
      "[CV]  criterion=entropy, min_samples_leaf=5, min_samples_split=10, n_estimators=50, score=0.8080808080808081, total=   0.1s\n",
      "[CV] criterion=entropy, min_samples_leaf=5, min_samples_split=10, n_estimators=100 \n",
      "[CV]  criterion=entropy, min_samples_leaf=5, min_samples_split=10, n_estimators=100, score=0.8080808080808081, total=   0.1s\n",
      "[CV] criterion=entropy, min_samples_leaf=5, min_samples_split=10, n_estimators=100 \n",
      "[CV]  criterion=entropy, min_samples_leaf=5, min_samples_split=10, n_estimators=100, score=0.8451178451178452, total=   0.1s\n",
      "[CV] criterion=entropy, min_samples_leaf=5, min_samples_split=10, n_estimators=100 \n",
      "[CV]  criterion=entropy, min_samples_leaf=5, min_samples_split=10, n_estimators=100, score=0.8282828282828283, total=   0.1s\n",
      "[CV] criterion=entropy, min_samples_leaf=5, min_samples_split=10, n_estimators=200 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  criterion=entropy, min_samples_leaf=5, min_samples_split=10, n_estimators=200, score=0.8114478114478114, total=   0.2s\n",
      "[CV] criterion=entropy, min_samples_leaf=5, min_samples_split=10, n_estimators=200 \n",
      "[CV]  criterion=entropy, min_samples_leaf=5, min_samples_split=10, n_estimators=200, score=0.8552188552188552, total=   0.2s\n",
      "[CV] criterion=entropy, min_samples_leaf=5, min_samples_split=10, n_estimators=200 \n",
      "[CV]  criterion=entropy, min_samples_leaf=5, min_samples_split=10, n_estimators=200, score=0.8282828282828283, total=   0.2s\n",
      "[CV] criterion=entropy, min_samples_leaf=5, min_samples_split=10, n_estimators=500 \n",
      "[CV]  criterion=entropy, min_samples_leaf=5, min_samples_split=10, n_estimators=500, score=0.8114478114478114, total=   0.5s\n",
      "[CV] criterion=entropy, min_samples_leaf=5, min_samples_split=10, n_estimators=500 \n",
      "[CV]  criterion=entropy, min_samples_leaf=5, min_samples_split=10, n_estimators=500, score=0.8552188552188552, total=   0.5s\n",
      "[CV] criterion=entropy, min_samples_leaf=5, min_samples_split=10, n_estimators=500 \n",
      "[CV]  criterion=entropy, min_samples_leaf=5, min_samples_split=10, n_estimators=500, score=0.8215488215488216, total=   0.6s\n",
      "[CV] criterion=entropy, min_samples_leaf=10, min_samples_split=2, n_estimators=30 \n",
      "[CV]  criterion=entropy, min_samples_leaf=10, min_samples_split=2, n_estimators=30, score=0.8080808080808081, total=   0.0s\n",
      "[CV] criterion=entropy, min_samples_leaf=10, min_samples_split=2, n_estimators=30 \n",
      "[CV]  criterion=entropy, min_samples_leaf=10, min_samples_split=2, n_estimators=30, score=0.8417508417508418, total=   0.0s\n",
      "[CV] criterion=entropy, min_samples_leaf=10, min_samples_split=2, n_estimators=30 \n",
      "[CV]  criterion=entropy, min_samples_leaf=10, min_samples_split=2, n_estimators=30, score=0.8013468013468014, total=   0.0s\n",
      "[CV] criterion=entropy, min_samples_leaf=10, min_samples_split=2, n_estimators=50 \n",
      "[CV]  criterion=entropy, min_samples_leaf=10, min_samples_split=2, n_estimators=50, score=0.8114478114478114, total=   0.0s\n",
      "[CV] criterion=entropy, min_samples_leaf=10, min_samples_split=2, n_estimators=50 \n",
      "[CV]  criterion=entropy, min_samples_leaf=10, min_samples_split=2, n_estimators=50, score=0.8417508417508418, total=   0.1s\n",
      "[CV] criterion=entropy, min_samples_leaf=10, min_samples_split=2, n_estimators=50 \n",
      "[CV]  criterion=entropy, min_samples_leaf=10, min_samples_split=2, n_estimators=50, score=0.8148148148148148, total=   0.1s\n",
      "[CV] criterion=entropy, min_samples_leaf=10, min_samples_split=2, n_estimators=100 \n",
      "[CV]  criterion=entropy, min_samples_leaf=10, min_samples_split=2, n_estimators=100, score=0.8013468013468014, total=   0.1s\n",
      "[CV] criterion=entropy, min_samples_leaf=10, min_samples_split=2, n_estimators=100 \n",
      "[CV]  criterion=entropy, min_samples_leaf=10, min_samples_split=2, n_estimators=100, score=0.8484848484848485, total=   0.1s\n",
      "[CV] criterion=entropy, min_samples_leaf=10, min_samples_split=2, n_estimators=100 \n",
      "[CV]  criterion=entropy, min_samples_leaf=10, min_samples_split=2, n_estimators=100, score=0.8181818181818182, total=   0.1s\n",
      "[CV] criterion=entropy, min_samples_leaf=10, min_samples_split=2, n_estimators=200 \n",
      "[CV]  criterion=entropy, min_samples_leaf=10, min_samples_split=2, n_estimators=200, score=0.8148148148148148, total=   0.2s\n",
      "[CV] criterion=entropy, min_samples_leaf=10, min_samples_split=2, n_estimators=200 \n",
      "[CV]  criterion=entropy, min_samples_leaf=10, min_samples_split=2, n_estimators=200, score=0.8417508417508418, total=   0.2s\n",
      "[CV] criterion=entropy, min_samples_leaf=10, min_samples_split=2, n_estimators=200 \n",
      "[CV]  criterion=entropy, min_samples_leaf=10, min_samples_split=2, n_estimators=200, score=0.8080808080808081, total=   0.2s\n",
      "[CV] criterion=entropy, min_samples_leaf=10, min_samples_split=2, n_estimators=500 \n",
      "[CV]  criterion=entropy, min_samples_leaf=10, min_samples_split=2, n_estimators=500, score=0.8047138047138047, total=   0.5s\n",
      "[CV] criterion=entropy, min_samples_leaf=10, min_samples_split=2, n_estimators=500 \n",
      "[CV]  criterion=entropy, min_samples_leaf=10, min_samples_split=2, n_estimators=500, score=0.8451178451178452, total=   0.5s\n",
      "[CV] criterion=entropy, min_samples_leaf=10, min_samples_split=2, n_estimators=500 \n",
      "[CV]  criterion=entropy, min_samples_leaf=10, min_samples_split=2, n_estimators=500, score=0.8114478114478114, total=   0.5s\n",
      "[CV] criterion=entropy, min_samples_leaf=10, min_samples_split=4, n_estimators=30 \n",
      "[CV]  criterion=entropy, min_samples_leaf=10, min_samples_split=4, n_estimators=30, score=0.8080808080808081, total=   0.0s\n",
      "[CV] criterion=entropy, min_samples_leaf=10, min_samples_split=4, n_estimators=30 \n",
      "[CV]  criterion=entropy, min_samples_leaf=10, min_samples_split=4, n_estimators=30, score=0.8451178451178452, total=   0.0s\n",
      "[CV] criterion=entropy, min_samples_leaf=10, min_samples_split=4, n_estimators=30 \n",
      "[CV]  criterion=entropy, min_samples_leaf=10, min_samples_split=4, n_estimators=30, score=0.8215488215488216, total=   0.0s\n",
      "[CV] criterion=entropy, min_samples_leaf=10, min_samples_split=4, n_estimators=50 \n",
      "[CV]  criterion=entropy, min_samples_leaf=10, min_samples_split=4, n_estimators=50, score=0.8047138047138047, total=   0.1s\n",
      "[CV] criterion=entropy, min_samples_leaf=10, min_samples_split=4, n_estimators=50 \n",
      "[CV]  criterion=entropy, min_samples_leaf=10, min_samples_split=4, n_estimators=50, score=0.8417508417508418, total=   0.1s\n",
      "[CV] criterion=entropy, min_samples_leaf=10, min_samples_split=4, n_estimators=50 \n",
      "[CV]  criterion=entropy, min_samples_leaf=10, min_samples_split=4, n_estimators=50, score=0.8181818181818182, total=   0.1s\n",
      "[CV] criterion=entropy, min_samples_leaf=10, min_samples_split=4, n_estimators=100 \n",
      "[CV]  criterion=entropy, min_samples_leaf=10, min_samples_split=4, n_estimators=100, score=0.8013468013468014, total=   0.1s\n",
      "[CV] criterion=entropy, min_samples_leaf=10, min_samples_split=4, n_estimators=100 \n",
      "[CV]  criterion=entropy, min_samples_leaf=10, min_samples_split=4, n_estimators=100, score=0.8451178451178452, total=   0.1s\n",
      "[CV] criterion=entropy, min_samples_leaf=10, min_samples_split=4, n_estimators=100 \n",
      "[CV]  criterion=entropy, min_samples_leaf=10, min_samples_split=4, n_estimators=100, score=0.8047138047138047, total=   0.1s\n",
      "[CV] criterion=entropy, min_samples_leaf=10, min_samples_split=4, n_estimators=200 \n",
      "[CV]  criterion=entropy, min_samples_leaf=10, min_samples_split=4, n_estimators=200, score=0.797979797979798, total=   0.2s\n",
      "[CV] criterion=entropy, min_samples_leaf=10, min_samples_split=4, n_estimators=200 \n",
      "[CV]  criterion=entropy, min_samples_leaf=10, min_samples_split=4, n_estimators=200, score=0.8417508417508418, total=   0.2s\n",
      "[CV] criterion=entropy, min_samples_leaf=10, min_samples_split=4, n_estimators=200 \n",
      "[CV]  criterion=entropy, min_samples_leaf=10, min_samples_split=4, n_estimators=200, score=0.8148148148148148, total=   0.2s\n",
      "[CV] criterion=entropy, min_samples_leaf=10, min_samples_split=4, n_estimators=500 \n",
      "[CV]  criterion=entropy, min_samples_leaf=10, min_samples_split=4, n_estimators=500, score=0.8114478114478114, total=   0.5s\n",
      "[CV] criterion=entropy, min_samples_leaf=10, min_samples_split=4, n_estimators=500 \n",
      "[CV]  criterion=entropy, min_samples_leaf=10, min_samples_split=4, n_estimators=500, score=0.8417508417508418, total=   0.5s\n",
      "[CV] criterion=entropy, min_samples_leaf=10, min_samples_split=4, n_estimators=500 \n",
      "[CV]  criterion=entropy, min_samples_leaf=10, min_samples_split=4, n_estimators=500, score=0.8080808080808081, total=   0.5s\n",
      "[CV] criterion=entropy, min_samples_leaf=10, min_samples_split=8, n_estimators=30 \n",
      "[CV]  criterion=entropy, min_samples_leaf=10, min_samples_split=8, n_estimators=30, score=0.8114478114478114, total=   0.0s\n",
      "[CV] criterion=entropy, min_samples_leaf=10, min_samples_split=8, n_estimators=30 \n",
      "[CV]  criterion=entropy, min_samples_leaf=10, min_samples_split=8, n_estimators=30, score=0.8417508417508418, total=   0.0s\n",
      "[CV] criterion=entropy, min_samples_leaf=10, min_samples_split=8, n_estimators=30 \n",
      "[CV]  criterion=entropy, min_samples_leaf=10, min_samples_split=8, n_estimators=30, score=0.8215488215488216, total=   0.0s\n",
      "[CV] criterion=entropy, min_samples_leaf=10, min_samples_split=8, n_estimators=50 \n",
      "[CV]  criterion=entropy, min_samples_leaf=10, min_samples_split=8, n_estimators=50, score=0.8080808080808081, total=   0.0s\n",
      "[CV] criterion=entropy, min_samples_leaf=10, min_samples_split=8, n_estimators=50 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  criterion=entropy, min_samples_leaf=10, min_samples_split=8, n_estimators=50, score=0.8383838383838383, total=   0.1s\n",
      "[CV] criterion=entropy, min_samples_leaf=10, min_samples_split=8, n_estimators=50 \n",
      "[CV]  criterion=entropy, min_samples_leaf=10, min_samples_split=8, n_estimators=50, score=0.8047138047138047, total=   0.1s\n",
      "[CV] criterion=entropy, min_samples_leaf=10, min_samples_split=8, n_estimators=100 \n",
      "[CV]  criterion=entropy, min_samples_leaf=10, min_samples_split=8, n_estimators=100, score=0.8114478114478114, total=   0.1s\n",
      "[CV] criterion=entropy, min_samples_leaf=10, min_samples_split=8, n_estimators=100 \n",
      "[CV]  criterion=entropy, min_samples_leaf=10, min_samples_split=8, n_estimators=100, score=0.8451178451178452, total=   0.1s\n",
      "[CV] criterion=entropy, min_samples_leaf=10, min_samples_split=8, n_estimators=100 \n",
      "[CV]  criterion=entropy, min_samples_leaf=10, min_samples_split=8, n_estimators=100, score=0.8080808080808081, total=   0.1s\n",
      "[CV] criterion=entropy, min_samples_leaf=10, min_samples_split=8, n_estimators=200 \n",
      "[CV]  criterion=entropy, min_samples_leaf=10, min_samples_split=8, n_estimators=200, score=0.8047138047138047, total=   0.2s\n",
      "[CV] criterion=entropy, min_samples_leaf=10, min_samples_split=8, n_estimators=200 \n",
      "[CV]  criterion=entropy, min_samples_leaf=10, min_samples_split=8, n_estimators=200, score=0.8383838383838383, total=   0.2s\n",
      "[CV] criterion=entropy, min_samples_leaf=10, min_samples_split=8, n_estimators=200 \n",
      "[CV]  criterion=entropy, min_samples_leaf=10, min_samples_split=8, n_estimators=200, score=0.8080808080808081, total=   0.2s\n",
      "[CV] criterion=entropy, min_samples_leaf=10, min_samples_split=8, n_estimators=500 \n",
      "[CV]  criterion=entropy, min_samples_leaf=10, min_samples_split=8, n_estimators=500, score=0.8047138047138047, total=   0.5s\n",
      "[CV] criterion=entropy, min_samples_leaf=10, min_samples_split=8, n_estimators=500 \n",
      "[CV]  criterion=entropy, min_samples_leaf=10, min_samples_split=8, n_estimators=500, score=0.8417508417508418, total=   0.6s\n",
      "[CV] criterion=entropy, min_samples_leaf=10, min_samples_split=8, n_estimators=500 \n",
      "[CV]  criterion=entropy, min_samples_leaf=10, min_samples_split=8, n_estimators=500, score=0.8215488215488216, total=   0.6s\n",
      "[CV] criterion=entropy, min_samples_leaf=10, min_samples_split=10, n_estimators=30 \n",
      "[CV]  criterion=entropy, min_samples_leaf=10, min_samples_split=10, n_estimators=30, score=0.8047138047138047, total=   0.0s\n",
      "[CV] criterion=entropy, min_samples_leaf=10, min_samples_split=10, n_estimators=30 \n",
      "[CV]  criterion=entropy, min_samples_leaf=10, min_samples_split=10, n_estimators=30, score=0.8383838383838383, total=   0.0s\n",
      "[CV] criterion=entropy, min_samples_leaf=10, min_samples_split=10, n_estimators=30 \n",
      "[CV]  criterion=entropy, min_samples_leaf=10, min_samples_split=10, n_estimators=30, score=0.7946127946127947, total=   0.0s\n",
      "[CV] criterion=entropy, min_samples_leaf=10, min_samples_split=10, n_estimators=50 \n",
      "[CV]  criterion=entropy, min_samples_leaf=10, min_samples_split=10, n_estimators=50, score=0.8181818181818182, total=   0.1s\n",
      "[CV] criterion=entropy, min_samples_leaf=10, min_samples_split=10, n_estimators=50 \n",
      "[CV]  criterion=entropy, min_samples_leaf=10, min_samples_split=10, n_estimators=50, score=0.8451178451178452, total=   0.1s\n",
      "[CV] criterion=entropy, min_samples_leaf=10, min_samples_split=10, n_estimators=50 \n",
      "[CV]  criterion=entropy, min_samples_leaf=10, min_samples_split=10, n_estimators=50, score=0.8047138047138047, total=   0.1s\n",
      "[CV] criterion=entropy, min_samples_leaf=10, min_samples_split=10, n_estimators=100 \n",
      "[CV]  criterion=entropy, min_samples_leaf=10, min_samples_split=10, n_estimators=100, score=0.8080808080808081, total=   0.1s\n",
      "[CV] criterion=entropy, min_samples_leaf=10, min_samples_split=10, n_estimators=100 \n",
      "[CV]  criterion=entropy, min_samples_leaf=10, min_samples_split=10, n_estimators=100, score=0.8383838383838383, total=   0.1s\n",
      "[CV] criterion=entropy, min_samples_leaf=10, min_samples_split=10, n_estimators=100 \n",
      "[CV]  criterion=entropy, min_samples_leaf=10, min_samples_split=10, n_estimators=100, score=0.8249158249158249, total=   0.1s\n",
      "[CV] criterion=entropy, min_samples_leaf=10, min_samples_split=10, n_estimators=200 \n",
      "[CV]  criterion=entropy, min_samples_leaf=10, min_samples_split=10, n_estimators=200, score=0.8080808080808081, total=   0.2s\n",
      "[CV] criterion=entropy, min_samples_leaf=10, min_samples_split=10, n_estimators=200 \n",
      "[CV]  criterion=entropy, min_samples_leaf=10, min_samples_split=10, n_estimators=200, score=0.8417508417508418, total=   0.2s\n",
      "[CV] criterion=entropy, min_samples_leaf=10, min_samples_split=10, n_estimators=200 \n",
      "[CV]  criterion=entropy, min_samples_leaf=10, min_samples_split=10, n_estimators=200, score=0.8114478114478114, total=   0.2s\n",
      "[CV] criterion=entropy, min_samples_leaf=10, min_samples_split=10, n_estimators=500 \n",
      "[CV]  criterion=entropy, min_samples_leaf=10, min_samples_split=10, n_estimators=500, score=0.8148148148148148, total=   0.6s\n",
      "[CV] criterion=entropy, min_samples_leaf=10, min_samples_split=10, n_estimators=500 \n",
      "[CV]  criterion=entropy, min_samples_leaf=10, min_samples_split=10, n_estimators=500, score=0.8417508417508418, total=   0.6s\n",
      "[CV] criterion=entropy, min_samples_leaf=10, min_samples_split=10, n_estimators=500 \n",
      "[CV]  criterion=entropy, min_samples_leaf=10, min_samples_split=10, n_estimators=500, score=0.8080808080808081, total=   0.5s\n",
      "Best accuracy:  0.8395061728395061\n",
      "Best params:  {'criterion': 'gini', 'min_samples_leaf': 1, 'min_samples_split': 10, 'n_estimators': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 360 out of 360 | elapsed:  1.3min finished\n"
     ]
    }
   ],
   "source": [
    "# Performing hyperparameter optimisation\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "grid_params = {\"criterion\": ['gini', 'entropy'],\n",
    "              \"n_estimators\": [30, 50, 100, 200, 500],\n",
    "              \"min_samples_leaf\": [1, 5, 10],\n",
    "              \"min_samples_split\": [2,4,8,10]}\n",
    "grid_cv = GridSearchCV(estimator = rf, param_grid = grid_params, scoring = 'accuracy', cv = 3, verbose = 3)\n",
    "grid_cv = grid_cv.fit(X_train, y_train)\n",
    "print(\"Best accuracy: \",grid_cv.best_score_)\n",
    "print(\"Best params: \", grid_cv.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=10,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=1,\n",
       "            oob_score=False, random_state=0, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit Random Forest Classifier to train set\n",
    "\n",
    "classifier = RandomForestClassifier(n_estimators = 100, criterion = 'gini', min_samples_leaf = 1, min_samples_split = 10, random_state = 0)\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict test set results\n",
    "y_pred = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the submissions file\n",
    "\n",
    "submission = pd.DataFrame({\n",
    "    'PassengerId': passenger_ids,\n",
    "    'Survived': y_pred\n",
    "})\n",
    "\n",
    "submission.to_csv('submissions3.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
